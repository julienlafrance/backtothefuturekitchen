# ğŸ“¦ Guide d'utilisation du S3 Storage

## ğŸ¯ Vue d'ensemble

Ce projet utilise **Garage S3** pour le stockage des donnÃ©es. Le systÃ¨me dÃ©tecte automatiquement votre environnement rÃ©seau pour optimiser les performances.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 Fast (NVMe) - Stockage haute performance   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Endpoint local:  http://192.168.80.202:3910   â”‚
â”‚  Endpoint externe: https://s3fast.lafrance.io   â”‚
â”‚  RÃ©gion: garage-fast                            â”‚
â”‚  Bucket: mangetamain                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ DÃ©tection automatique du rÃ©seau

Le module `utils/utils_s3.py` dÃ©tecte automatiquement votre environnement :

- **RÃ©seau local** (`192.168.80.x` ou `192.168.0.x`) â†’ Utilise l'IP directe (ultra-rapide âš¡)
- **RÃ©seau externe** â†’ Utilise le reverse proxy HTTPS (sÃ©curisÃ© ğŸ”’)

## ğŸš€ DÃ©marrage rapide

### Import du module

```python
import sys
sys.path.insert(0, '..')  # Depuis un sous-dossier
from utils.utils_s3 import get_s3_client, get_duckdb_s3_connection
```

### 1. Connexion S3 classique

```python
from utils.utils_s3 import get_s3_client

# Connexion automatique
client, bucket = get_s3_client()
```

### 2. Lister les fichiers

```python
response = client.list_objects_v2(Bucket=bucket)

for obj in response.get('Contents', []):
    print(f"ğŸ“„ {obj['Key']} - {obj['Size']} bytes")
```

### 3. TÃ©lÃ©charger un fichier

```python
# TÃ©lÃ©charger un fichier spÃ©cifique
client.download_file(
    Bucket=bucket,
    Key='mangetamain.duckdb',
    Filename='data/mangetamain.duckdb'
)
```

## ğŸ¦† DuckDB avec S3 (RecommandÃ©)

### Connexion directe (sans tÃ©lÃ©chargement !)

```python
from utils.utils_s3 import get_duckdb_s3_connection

# Connexion DuckDB avec S3 configurÃ© automatiquement
con, bucket = get_duckdb_s3_connection()
```

### Query directe sur fichier CSV S3

```python
# Lire directement depuis S3 - AUCUN tÃ©lÃ©chargement !
df = con.execute(f"SELECT * FROM 's3://{bucket}/PP_recipes.csv' LIMIT 5").df()
print(df)
```

### Query sur base DuckDB S3

```python
# Lire la base DuckDB directement depuis S3
df = con.execute(f"SELECT * FROM 's3://{bucket}/mangetamain.duckdb::recipes' LIMIT 5").df()
print(df)
```

### AgrÃ©gations complexes

```python
# Analyse directe sur S3 sans tÃ©lÃ©chargement
query = f"""
SELECT 
    calorie_level,
    COUNT(*) as nb_recipes,
    AVG(n_ingredients) as avg_ingredients
FROM 's3://{bucket}/PP_recipes.csv'
GROUP BY calorie_level
ORDER BY calorie_level
"""

df = con.execute(query).df()
print(df)
```

## âš™ï¸ Options avancÃ©es

### Mode verbose

Pour voir les informations de connexion :

```python
client, bucket = get_s3_client(verbose=True)
# ğŸ”— S3 Endpoint: local (direct)
```

### Forcer l'endpoint externe

Utile pour tester ou contourner des problÃ¨mes rÃ©seau :

```python
client, bucket = get_s3_client(force_external=True)
```

### Utiliser un profil diffÃ©rent

Si vous avez plusieurs profils S3 configurÃ©s :

```python
client, bucket = get_s3_client(profile='autre_profil')
```

## ğŸ“Š Performances

| Environnement | Endpoint | Temps (1.4GB) | DÃ©bit |
|---------------|----------|---------------|-------|
| **VM locale** | Direct (3910) | ~2.7s | ~523 MB/s âš¡ |
| **VM via HTTPS** | Reverse proxy | ~13s | ~107 MB/s |
| **HÃ´te ixia** | Localhost | ~1.9s | ~718 MB/s ğŸš€ |

ğŸ’¡ **Astuce** : La dÃ©tection automatique utilise toujours le mode le plus rapide disponible !

## ğŸ”’ SÃ©curitÃ©

### Credentials

Les credentials sont stockÃ©s dans `96_keys/credentials` (ignorÃ© par git).

**Structure du fichier :**

```ini
[s3fast]
aws_access_key_id = GK4feb...
aws_secret_access_key = 50e63b...
endpoint_url = https://s3fast.lafrance.io
region = garage-fast
bucket = mangetamain
```

âš ï¸ **IMPORTANT** : Ne JAMAIS commit les credentials dans git !

### VÃ©rifier le .gitignore

Le dossier `96_keys/` doit Ãªtre dans `.gitignore` :

```bash
# Dans /home/dataia25/mangetamain/.gitignore
96_keys/
```

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨me de connexion

```python
# Tester la connexion
from utils.utils_s3 import get_s3_client

try:
    client, bucket = get_s3_client(verbose=True)
    print(f"âœ… Connexion rÃ©ussie au bucket: {bucket}")
except Exception as e:
    print(f"âŒ Erreur: {e}")
```

### VÃ©rifier le rÃ©seau

```python
from utils.utils_s3 import is_on_local_network

if is_on_local_network():
    print("ğŸ“ Vous Ãªtes sur le rÃ©seau local")
else:
    print("ğŸŒ Vous Ãªtes sur un rÃ©seau externe")
```

### Credentials introuvables

Si vous voyez l'erreur `Credentials introuvable`, vÃ©rifiez :

```bash
# Le fichier doit exister ici :
ls -la 96_keys/credentials

# Si absent, contactez l'administrateur
```

## ğŸ“š Exemples complets

### Exemple 1 : Analyse DuckDB sur CSV S3

```python
import sys
sys.path.insert(0, '..')
from utils.utils_s3 import get_duckdb_s3_connection

# Connexion directe S3
con, bucket = get_duckdb_s3_connection()

# Analyse directe sans tÃ©lÃ©chargement
query = f"""
SELECT 
    calorie_level,
    COUNT(*) as recipes_count,
    ROUND(AVG(n_ingredients), 2) as avg_ingredients,
    ROUND(AVG(minutes), 2) as avg_cooking_time
FROM 's3://{bucket}/PP_recipes.csv'
WHERE n_ingredients BETWEEN 5 AND 15
GROUP BY calorie_level
ORDER BY recipes_count DESC
"""

df = con.execute(query).df()
print("ğŸ“Š Analyse des recettes par niveau calorique:")
print(df)
```

### Exemple 2 : Comparaison de fichiers S3

```python
# Comparer deux datasets directement sur S3
query = f"""
SELECT 
    'recipes' as source,
    COUNT(*) as count,
    AVG(n_ingredients) as avg_ingredients
FROM 's3://{bucket}/PP_recipes.csv'

UNION ALL

SELECT 
    'interactions' as source,
    COUNT(*) as count,
    NULL as avg_ingredients
FROM 's3://{bucket}/PP_user_interactions.csv'
"""

df = con.execute(query).df()
print("ğŸ“ˆ Comparaison des datasets:")
print(df)
```

### Exemple 3 : Export de rÃ©sultats vers S3

```python
from utils.utils_s3 import get_s3_client, get_duckdb_s3_connection
import pandas as pd

# Analyse avec DuckDB
con, bucket = get_duckdb_s3_connection()
df_results = con.execute(f"SELECT * FROM 's3://{bucket}/PP_recipes.csv' LIMIT 100").df()

# Sauvegarder localement
df_results.to_csv('analysis_results.csv', index=False)

# Upload vers S3
client, bucket = get_s3_client()
client.upload_file('analysis_results.csv', bucket, 'results/analysis_results.csv')
print("âœ… RÃ©sultats uploadÃ©s sur S3")
```

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- VÃ©rifiez d'abord ce README
- Testez avec `verbose=True` pour plus d'informations
- Contactez l'Ã©quipe infrastructure pour les problÃ¨mes de credentials

---

**DerniÃ¨re mise Ã  jour** : 2025-10-08  
**Responsable** : Infrastructure Team
