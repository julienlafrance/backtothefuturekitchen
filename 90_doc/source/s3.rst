Stockage S3 Garage
==================

Configuration et utilisation du stockage S3 Garage haute performance.

Vue d'ensemble
--------------

**Endpoint unique**: http://s3fast.lafrance.io

**Bucket**: mangetamain

**Performance**: 500-917 MB/s (DNAT bypass)

**Région**: garage-fast

Installation
------------

Configuration DNS Locale
^^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: bash

   echo "192.168.80.202  s3fast.lafrance.io" | sudo tee -a /etc/hosts

Installation iptables-persistent
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: bash

   sudo apt update
   sudo apt install iptables-persistent -y

Règle iptables DNAT
^^^^^^^^^^^^^^^^^^^^

Bypass du reverse proxy pour performance maximale:

.. code-block:: bash

   sudo iptables -t nat -A OUTPUT -p tcp -d 192.168.80.202 --dport 80 -j DNAT --to-destination 192.168.80.202:3910

Sauvegarde Permanente
^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: bash

   sudo netfilter-persistent save

Vérification Installation
^^^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: bash

   # DNS
   getent hosts s3fast.lafrance.io
   # Doit afficher: 192.168.80.202  s3fast.lafrance.io

   # iptables
   sudo iptables -t nat -L OUTPUT -n -v | grep 3910
   # Doit afficher la règle DNAT

Configuration Credentials
--------------------------

Structure 96_keys/
^^^^^^^^^^^^^^^^^^

.. code-block:: text

   96_keys/
   ├── credentials          # Profil s3fast
   ├── aws_config           # Config AWS CLI
   └── garage_s3.duckdb     # Base DuckDB avec secret S3

Fichier credentials
^^^^^^^^^^^^^^^^^^^

Format ConfigParser:

.. code-block:: ini

   [s3fast]
   aws_access_key_id = GK4feb...
   aws_secret_access_key = 50e63b...
   endpoint_url = http://s3fast.lafrance.io
   region = garage-fast
   bucket = mangetamain

Fichier aws_config
^^^^^^^^^^^^^^^^^^

Format AWS CLI:

.. code-block:: ini

   [profile s3fast]
   region = garage-fast
   s3 =
       endpoint_url = http://s3fast.lafrance.io

Base DuckDB avec Secret
^^^^^^^^^^^^^^^^^^^^^^^^

Créer une fois:

.. code-block:: bash

   cd ~/mangetamain/96_keys
   duckdb garage_s3.duckdb

Dans DuckDB:

.. code-block:: sql

   INSTALL httpfs;
   LOAD httpfs;

   CREATE SECRET s3fast (
       TYPE s3,
       KEY_ID 'votre_access_key_id',
       SECRET 'votre_secret_access_key',
       ENDPOINT 's3fast.lafrance.io',
       REGION 'garage-fast',
       URL_STYLE 'path',
       USE_SSL false
   );

Utilisation AWS CLI
-------------------

Liste Fichiers
^^^^^^^^^^^^^^

.. code-block:: bash

   aws s3 ls s3://mangetamain/ \
     --endpoint-url http://s3fast.lafrance.io \
     --region garage-fast

Download
^^^^^^^^

.. code-block:: bash

   aws s3 cp s3://mangetamain/PP_recipes.csv /tmp/recipes.csv \
     --endpoint-url http://s3fast.lafrance.io \
     --region garage-fast

Upload
^^^^^^

.. code-block:: bash

   aws s3 cp /tmp/results.csv s3://mangetamain/results/ \
     --endpoint-url http://s3fast.lafrance.io \
     --region garage-fast

Utilisation Python boto3
-------------------------

Chargement Credentials
^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: python

   import boto3
   from configparser import ConfigParser

   # Charger credentials depuis 96_keys/
   config = ConfigParser()
   config.read('../96_keys/credentials')

   s3 = boto3.client(
       's3',
       endpoint_url=config['s3fast']['endpoint_url'],
       aws_access_key_id=config['s3fast']['aws_access_key_id'],
       aws_secret_access_key=config['s3fast']['aws_secret_access_key'],
       region_name=config['s3fast']['region']
   )

Liste Objets
^^^^^^^^^^^^

.. code-block:: python

   # Liste fichiers avec tailles
   response = s3.list_objects_v2(Bucket='mangetamain')
   for obj in response.get('Contents', []):
       print(f"{obj['Key']} - {obj['Size']/1e6:.1f} MB")

Download Fichier
^^^^^^^^^^^^^^^^

.. code-block:: python

   s3.download_file('mangetamain', 'PP_recipes.csv', '/tmp/recipes.csv')

Upload Fichier
^^^^^^^^^^^^^^

.. code-block:: python

   s3.upload_file('/tmp/results.csv', 'mangetamain', 'results/analysis.csv')

Utilisation DuckDB
------------------

Requêtes SQL sur S3
^^^^^^^^^^^^^^^^^^^

En CLI:

.. code-block:: bash

   # Requête simple
   duckdb ~/mangetamain/96_keys/garage_s3.duckdb \
     -c "SELECT COUNT(*) FROM 's3://mangetamain/PP_recipes.csv'"

   # Analyse avec GROUP BY
   duckdb ~/mangetamain/96_keys/garage_s3.duckdb -c "
   SELECT calorie_level, COUNT(*) as total
   FROM 's3://mangetamain/PP_recipes.csv'
   GROUP BY calorie_level
   ORDER BY total DESC"

En Python:

.. code-block:: python

   import duckdb

   # Connexion à la base avec secret
   conn = duckdb.connect('~/mangetamain/96_keys/garage_s3.duckdb')

   # Requête SQL directe sur S3
   df = conn.execute("""
       SELECT *
       FROM 's3://mangetamain/PP_recipes.csv'
       LIMIT 1000
   """).fetchdf()

Parquet sur S3
^^^^^^^^^^^^^^

DuckDB optimisé pour Parquet:

.. code-block:: python

   # Lecture Parquet depuis S3 (zero-copy)
   conn.execute("""
       SELECT AVG(calories) as mean_calories
       FROM 's3://mangetamain/RAW_recipes_clean.parquet'
       WHERE year >= 2010
   """)

Utilisation Polars
------------------

Lecture Directe S3
^^^^^^^^^^^^^^^^^^

.. code-block:: python

   import polars as pl
   from configparser import ConfigParser

   # Charger credentials
   config = ConfigParser()
   config.read('../96_keys/credentials')

   # Configuration storage options
   storage_options = {
       'aws_endpoint_url': config['s3fast']['endpoint_url'],
       'aws_access_key_id': config['s3fast']['aws_access_key_id'],
       'aws_secret_access_key': config['s3fast']['aws_secret_access_key'],
       'aws_region': config['s3fast']['region']
   }

   # Lecture CSV depuis S3
   df = pl.read_csv(
       's3://mangetamain/PP_recipes.csv',
       storage_options=storage_options
   )

   # Lecture Parquet depuis S3
   df = pl.read_parquet(
       's3://mangetamain/RAW_recipes_clean.parquet',
       storage_options=storage_options
   )

Tests Performance
-----------------

Benchmark Download
^^^^^^^^^^^^^^^^^^

.. code-block:: bash

   # Test avec fichier volumineux
   time aws s3 cp s3://mangetamain/large_file.parquet /tmp/ \
     --endpoint-url http://s3fast.lafrance.io \
     --region garage-fast

**Résultats attendus**:

* **Avec DNAT bypass**: 500-917 MB/s
* **Sans bypass** (reverse proxy): 50-100 MB/s
* **Gain**: 5-10x plus rapide

Vérification DNAT Actif
^^^^^^^^^^^^^^^^^^^^^^^^

.. code-block:: bash

   # Vérifier iptables rule
   sudo iptables -t nat -L OUTPUT -n -v | grep 3910

   # Test connexion directe port 3910
   curl -I http://192.168.80.202:3910/mangetamain/

   # Doit retourner HTTP 200 ou XML erreur S3

Structure Bucket
----------------

Organisation Fichiers
^^^^^^^^^^^^^^^^^^^^^

.. code-block:: text

   s3://mangetamain/
   ├── RAW_recipes.csv
   ├── RAW_recipes_clean.parquet
   ├── RAW_interactions.csv
   ├── RAW_interactions_clean.parquet
   ├── PP_recipes.csv
   ├── PP_users.csv
   ├── PP_ratings.parquet
   ├── interactions_train.csv
   ├── interactions_test.csv
   └── interactions_validation.csv

Tailles Fichiers
^^^^^^^^^^^^^^^^

=========================================== ============
Fichier                                     Taille
=========================================== ============
RAW_recipes.csv                             ~50 MB
RAW_recipes_clean.parquet                   ~25 MB
RAW_interactions.csv                        ~200 MB
RAW_interactions_clean.parquet              ~80 MB
PP_recipes.csv                              ~30 MB
PP_ratings.parquet                          ~60 MB
=========================================== ============

Tests Infrastructure
--------------------

Tests Automatiques (50_test/)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**S3_duckdb_test.py** (14 tests):

* Environnement système (AWS CLI, credentials)
* Connexion S3 avec boto3
* Performance download (>5 MB/s)
* DuckDB + S3 intégration
* Tests Docker (optionnels)

**test_s3_parquet_files.py** (5 tests):

* Scanne automatiquement le code
* Trouve les références aux fichiers parquet
* Teste l'accessibilité S3

Lancer Tests S3
^^^^^^^^^^^^^^^

.. code-block:: bash

   cd 50_test
   pytest S3_duckdb_test.py -v

Dépannage
---------

Erreur: Cannot connect to S3
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Causes possibles**:

1. DNS non configuré
2. Règle iptables manquante
3. Credentials invalides

**Solution**:

.. code-block:: bash

   # Vérifier DNS
   getent hosts s3fast.lafrance.io

   # Vérifier iptables
   sudo iptables -t nat -L OUTPUT -n -v | grep 3910

   # Tester credentials
   aws s3 ls s3://mangetamain/ \
     --endpoint-url http://s3fast.lafrance.io \
     --region garage-fast

Erreur: Slow Download Speed
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Cause**: DNAT bypass non actif, trafic passe par reverse proxy

**Solution**: Vérifier règle iptables

.. code-block:: bash

   sudo iptables -t nat -L OUTPUT -n -v | grep 3910

   # Si absent, recréer règle
   sudo iptables -t nat -A OUTPUT -p tcp -d 192.168.80.202 --dport 80 -j DNAT --to-destination 192.168.80.202:3910
   sudo netfilter-persistent save

Erreur: DuckDB Secret Not Found
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**Cause**: Secret S3 non créé dans base DuckDB

**Solution**: Recréer le secret

.. code-block:: bash

   duckdb ~/mangetamain/96_keys/garage_s3.duckdb

.. code-block:: sql

   DROP SECRET IF EXISTS s3fast;

   CREATE SECRET s3fast (
       TYPE s3,
       KEY_ID 'your_key_id',
       SECRET 'your_secret',
       ENDPOINT 's3fast.lafrance.io',
       REGION 'garage-fast',
       URL_STYLE 'path',
       USE_SSL false
   );

Bonnes Pratiques
----------------

Sécurité Credentials
^^^^^^^^^^^^^^^^^^^^^

* **JAMAIS** commiter 96_keys/ (dans .gitignore)
* Partager credentials via canal sécurisé uniquement
* Rotation régulière des clés

Performance
^^^^^^^^^^^

* Privilégier Parquet sur CSV (2-3x plus rapide)
* Utiliser DuckDB pour requêtes SQL (zero-copy)
* Activer DNAT bypass (10x plus rapide)
* Cache local pour fichiers fréquemment accédés

Cache Streamlit
^^^^^^^^^^^^^^^

.. code-block:: python

   import streamlit as st

   @st.cache_data(ttl=3600)  # Cache 1h
   def load_data_from_s3():
       """Charge données S3 avec cache."""
       # Lecture S3 coûteuse une seule fois
       return df

Voir Aussi
----------

* :doc:`installation` - Installation complète du projet
* :doc:`tests` - Tests infrastructure S3 (50_test/)
* :doc:`api/infrastructure` - Module data.cached_loaders
* S3_INSTALL.md (racine) - Documentation détaillée installation
* S3_USAGE.md (racine) - Guide d'utilisation complet
