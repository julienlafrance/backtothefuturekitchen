# üß™ Tests d'Infrastructure - 50_test/

## Vue d'ensemble

Le r√©pertoire `50_test/` contient des **tests d'infrastructure** pour valider la configuration S3, DuckDB et les requ√™tes SQL du projet. Contrairement aux tests unitaires classiques, ces tests v√©rifient l'**int√©gration avec les services externes** (S3, DuckDB).

## Pourquoi pas de coverage ici ?

Les tests d'infrastructure **ne n√©cessitent pas de coverage** car :

1. **Pas de code m√©tier** - Ce sont des tests de validation, pas du code de production
2. **Tests d'int√©gration** - V√©rifient les connexions S3, DuckDB, Docker
3. **Automatisation de validation** - Scannent automatiquement le code pour trouver les fichiers parquet et requ√™tes SQL

**Le coverage est pertinent pour** : 10_preprod, 20_prod, 00_eda (code m√©tier)
**Le coverage n'est PAS pertinent pour** : 50_test (tests d'infrastructure)

---

## Architecture des tests

```
50_test/
‚îú‚îÄ‚îÄ S3_duckdb_test.py           # Tests S3 + DuckDB (14 tests)
‚îú‚îÄ‚îÄ test_s3_parquet_files.py    # Validation parquet files (5 tests)
‚îú‚îÄ‚îÄ test_sql_queries.py         # Validation requ√™tes SQL (16 tests)
‚îú‚îÄ‚îÄ pyproject.toml              # Configuration pytest (sans coverage)
‚îî‚îÄ‚îÄ README_TESTS.md             # Ce fichier
```

---

## 1. S3_duckdb_test.py (14 tests)

### Objectif
Tests complets de l'infrastructure S3 + DuckDB avec connexion au bucket Garage.

### Tests effectu√©s

#### üì¶ Environnement (4 tests)
- `test_environment_hostname` - V√©rifie le hostname
- `test_environment_ip` - D√©tecte l'IP et le r√©seau local
- `test_credentials_file_exists` - V√©rifie `96_keys/credentials`
- `test_duckdb_file_exists` - V√©rifie `96_keys/garage_s3.duckdb`

#### üîå Connexion S3 (2 tests)
- `test_s3_client_creation` - Cr√©e le client boto3
- `test_s3_bucket_accessible` - Liste les objets du bucket
- `test_s3_list_all_objects` - Statistiques compl√®tes du bucket

#### ‚ö° Performance (1 test)
- `test_s3_download_performance` - T√©l√©charge un fichier et mesure la vitesse
  - **Objectif**: > 5 MB/s
  - **R√©sultat typique**: ~8.8 MB/s

#### üóÑÔ∏è DuckDB + S3 (3 tests)
- `test_duckdb_s3_count_recipes` - `COUNT(*)` sur CSV S3
- `test_duckdb_s3_group_by` - `GROUP BY` sur CSV S3
- `test_duckdb_s3_parquet_file` - Lecture fichier parquet S3

#### üê≥ Docker (4 tests - optionnels)
- `test_docker_containers_running` - Liste les containers actifs
- `test_docker_s3_in_containers` - Teste boto3 dans mange_preprod et mange_prod

**Note**: Les tests Docker sont **skip automatiquement** si Docker n'est pas disponible.

### Configuration S3

```python
# Lecture depuis 96_keys/credentials
[s3fast]
aws_access_key_id = GK...
aws_secret_access_key = 50e...
endpoint_url = http://s3fast.lafrance.io
region = garage-fast
```

### Fixtures pytest

```python
@pytest.fixture(scope="module")
def s3_config(credentials_file):
    """Charge la config S3 depuis credentials"""

@pytest.fixture(scope="module")
def s3_client(s3_config):
    """Cr√©e le client boto3 S3"""

@pytest.fixture(scope="module")
def duckdb_connection(s3_config):
    """Connexion DuckDB avec secret S3"""
```

### Commandes

```bash
# Tous les tests
pytest S3_duckdb_test.py -v

# Avec output d√©taill√©
pytest S3_duckdb_test.py -v -s

# Tests sp√©cifiques
pytest S3_duckdb_test.py::test_s3_bucket_accessible -v
pytest S3_duckdb_test.py::test_duckdb_s3_count_recipes -v
```

---

## 2. test_s3_parquet_files.py (5 tests)

### Objectif
**Scanne automatiquement** tous les fichiers `.py` et `.ipynb` du projet pour trouver les r√©f√©rences aux fichiers parquet, puis v√©rifie leur accessibilit√© sur S3.

### Logique de d√©tection

```python
def extract_parquet_files_from_code() -> Dict[str, List[str]]:
    """
    Scanne 00_eda, 10_preprod, 20_prod

    Returns:
        {
            'interactions_sample.parquet': [
                '00_eda/notebook.ipynb',
                '10_preprod/src/module.py'
            ]
        }
    """
```

**Patterns d√©tect√©s:**
- `s3://mangetamain/file.parquet`
- `'file.parquet'` ou `"file.parquet"`
- `FROM 'file.parquet'` (dans SQL)

### Tests effectu√©s

1. **test_parquet_files_discovered** - V√©rifie qu'au moins 1 fichier est trouv√©
2. **test_parquet_accessible** - Teste `COUNT(*)` sur chaque parquet (parametrized)
3. **test_parquet_schema** - Lit le sch√©ma (colonnes) de chaque parquet
4. **test_parquet_sample_data** - Lit 5 lignes de chaque parquet
5. **test_all_parquet_files_summary** - R√©sum√© global avec statistiques

### Exemple de r√©sultat

```
üìã Fichiers parquet d√©couverts: 1
   ‚Ä¢ interactions_sample.parquet
     ‚îî‚îÄ 00_eda/09_test/analyse_ratings_simple_clean.py
     ‚îî‚îÄ 10_preprod/src/mangetamain_analytics/visualization/analyse_ratings_simple.py

‚úÖ interactions_sample.parquet
   ‚îú‚îÄ 50,000 lignes √ó 6 colonnes
   ‚îî‚îÄ Utilis√© par 2 fichier(s)
```

### Commandes

```bash
# Tous les tests
pytest test_s3_parquet_files.py -v -s

# D√©couverte seulement
pytest test_s3_parquet_files.py::test_parquet_files_discovered -v

# Scan manuel (sans tests)
python test_s3_parquet_files.py
```

---

## 3. test_sql_queries.py (16 tests)

### Objectif
**Scanne automatiquement** tous les fichiers `.py` et `.ipynb` pour extraire les requ√™tes SQL, puis teste leur syntaxe et ex√©cutabilit√©.

### Logique de d√©tection

```python
def extract_sql_queries_from_code() -> Dict[str, List[Dict]]:
    """
    Trouve toutes les requ√™tes SQL dans le projet

    Returns:
        {
            'file.py': [
                {
                    'query': 'SELECT * FROM table',
                    'line': 42,
                    'is_complete': True
                }
            ]
        }
    """
```

**Patterns d√©tect√©s:**
- `conn.execute("""SELECT...""")`
- `sql = """SELECT..."""`
- `QUERY = f"""SELECT..."""`
- Fonctionne avec triple quotes et f-strings

### Nettoyage et validation

```python
def clean_sql_query(query: str) -> tuple[str, bool]:
    """
    Nettoie une requ√™te et v√©rifie si elle est testable

    Returns:
        (cleaned_query, is_complete)

    is_complete = True si:
    - Contient SELECT et FROM
    - Pas de templates {variable}
    - Pas de code Python m√©lang√©
    """
```

**Exemples de requ√™tes filtr√©es:**
- ‚ùå `SELECT * FROM {table_name}` - Template non r√©solu
- ‚ùå `SELECT * FROM iris` - Exemple g√©n√©rique
- ‚úÖ `SELECT * FROM 's3://mangetamain/file.csv'` - Requ√™te compl√®te

### Tests effectu√©s

1. **test_sql_queries_discovered** - Affiche les statistiques de d√©couverte
2. **test_sql_query_valid_syntax** - Teste `EXPLAIN query` (parametrized)
3. **test_sql_query_executable** - Ex√©cute `query LIMIT 1` (parametrized)
4. **test_sql_queries_summary** - R√©sum√© global avec cat√©gorisation

### Exemple de r√©sultat

```
üìã Requ√™tes SQL d√©couvertes:
   ‚Ä¢ Total: 27
   ‚Ä¢ Compl√®tes (testables): 7
   ‚Ä¢ Incompl√®tes (templates): 20

üìÑ Requ√™tes testables par fichier:

   10_preprod/src/mangetamain_analytics/visualization/analyse_ratings_simple.py
      ‚îî‚îÄ ligne 51: SELECT rating, COUNT(*) as count FROM 's3://...

   00_eda/09_test/test_module.py
      ‚îî‚îÄ ligne 33: SELECT * FROM RAW_interactions WHERE rating...

üîç Types de requ√™tes:
   ‚Ä¢ Requ√™tes S3: 3
   ‚Ä¢ Requ√™tes sur tables DuckDB: 4
```

### Commandes

```bash
# Tous les tests
pytest test_sql_queries.py -v -s

# D√©couverte seulement
pytest test_sql_queries.py::test_sql_queries_discovered -v

# Test syntaxe seulement
pytest test_sql_queries.py -k "valid_syntax" -v

# Scan manuel
python test_sql_queries.py
```

---

## Configuration pytest

### pyproject.toml

```toml
[project]
dependencies = [
    "boto3>=1.40.48",
    "duckdb>=1.4.1",
    "pytest>=8.0.0",
    "pytest-cov>=6.0.0",
    "pandas>=2.0.0",
]

[tool.pytest.ini_options]
testpaths = ["."]
python_files = ["test_*.py", "S3_duckdb_test.py"]
addopts = ["-v"]  # Pas de coverage pour les tests d'infrastructure
```

**Note importante:** Pas de `--cov` dans `addopts` car ce sont des tests d'infrastructure.

---

## Ex√©cution des tests

### Sur machine locale

```bash
cd 50_test

# Tous les tests (sauf Docker)
pytest -v

# Tests S3 + DuckDB seulement
pytest S3_duckdb_test.py -v

# Tests parquet seulement
pytest test_s3_parquet_files.py -v

# Tests SQL seulement
pytest test_sql_queries.py -v
```

**R√©sultat local:** 14-16 tests passent (Docker skip)

### Sur serveur (dataia)

```bash
ssh dataia
cd mangetamain/000_dev/50_test

# Installer les d√©pendances
uv sync

# Lancer tous les tests
uv run pytest -v
```

**R√©sultat serveur:** 35 tests passent (Docker disponible)

---

## R√©sultats attendus

### ‚úÖ Tests qui doivent passer

- **Environnement** - Hostname, IP, credentials
- **S3 connexion** - Client boto3, bucket accessible
- **S3 performance** - Download > 5 MB/s
- **DuckDB + S3** - COUNT, GROUP BY, lecture parquet
- **Parquet files** - Tous les fichiers r√©f√©renc√©s sont accessibles
- **SQL queries** - Syntaxe valide et ex√©cutable

### ‚ö†Ô∏è Tests qui peuvent skip

- **Docker tests** - Si Docker n'est pas disponible localement
- **Fichiers parquet** - Si aucun parquet r√©f√©renc√© dans le code

### ‚ùå Tests qui indiquent un probl√®me

- **S3 non accessible** - V√©rifier credentials ou r√©seau
- **DuckDB erreur** - V√©rifier installation DuckDB
- **Parquet introuvable** - Fichier manquant sur S3
- **SQL √©choue** - Table manquante ou syntaxe incorrecte

---

## D√©pannage

### Erreur: "Credentials file not found"

```bash
# V√©rifier l'existence du fichier
ls -la ../96_keys/credentials

# Le fichier doit contenir:
[s3fast]
aws_access_key_id = ...
aws_secret_access_key = ...
```

### Erreur: "No data was collected" (coverage)

C'est normal! Les tests d'infrastructure n'ont pas besoin de coverage.

### Erreur: "Bucket not accessible"

```bash
# Tester la connexion manuellement
python -c "
import boto3
from configparser import ConfigParser

config = ConfigParser()
config.read('../96_keys/credentials')

s3 = boto3.client(
    's3',
    endpoint_url='http://s3fast.lafrance.io',
    aws_access_key_id=config['s3fast']['aws_access_key_id'],
    aws_secret_access_key=config['s3fast']['aws_secret_access_key']
)

print(s3.list_objects_v2(Bucket='mangetamain', MaxKeys=5))
"
```

### Tests Docker skip

Normal sur machine locale. Les tests Docker ne s'ex√©cutent que sur le serveur.

---

## Bonnes pratiques

### ‚úÖ √Ä faire

1. **Lancer les tests avant commit** - Valide que tout fonctionne
2. **V√©rifier les nouveaux parquets** - Ajouter au S3 avant de les r√©f√©rencer
3. **Tester les nouvelles requ√™tes SQL** - S'assurer qu'elles sont compl√®tes
4. **Mettre √† jour les credentials** - Si changement de cl√©s S3

### ‚ùå √Ä √©viter

1. **Ne pas ajouter de coverage** - Pas pertinent pour tests d'infrastructure
2. **Ne pas commit les credentials** - Toujours dans 96_keys/ (gitignore)
3. **Ne pas tester en production** - Tests safe mais utiliser preprod quand possible
4. **Ne pas ignorer les warnings** - Peuvent indiquer des probl√®mes

---

## Ajout de nouveaux tests

### 1. Ajouter un nouveau fichier parquet

Le test le d√©tectera automatiquement! Il suffit de:

```python
# Dans votre code
df = conn.execute("SELECT * FROM 's3://mangetamain/nouveau_fichier.parquet'").df()
```

Au prochain `pytest test_s3_parquet_files.py`, il sera test√©.

### 2. Ajouter une nouvelle requ√™te SQL

Le test la d√©tectera automatiquement! Il suffit de:

```python
# Dans votre code
result = conn.execute("""
    SELECT column1, COUNT(*) as count
    FROM ma_table
    GROUP BY column1
""").fetchdf()
```

Au prochain `pytest test_sql_queries.py`, elle sera test√©e.

### 3. Ajouter un test d'infrastructure

Cr√©er un nouveau fichier `test_nouvelle_feature.py`:

```python
import pytest

def test_ma_nouvelle_infrastructure():
    """Test de validation de nouvelle infrastructure"""
    # Setup
    connexion = create_connection()

    # Test
    result = connexion.test_feature()

    # Validation
    assert result is not None
    assert result.status == "OK"
```

---

## Int√©gration CI/CD

Ces tests sont id√©aux pour CI/CD car ils valident l'infrastructure compl√®te:

```yaml
# .github/workflows/test-infrastructure.yml
name: Infrastructure Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Install dependencies
        run: |
          cd 50_test
          uv sync

      - name: Run infrastructure tests
        run: |
          cd 50_test
          uv run pytest -v --junit-xml=test-results.xml
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
```

---

## R√©sum√©

**50_test/** contient des **tests d'infrastructure** qui:

1. ‚úÖ Valident S3 + DuckDB + Docker
2. üîç Scannent automatiquement le code pour trouver parquets et SQL
3. ‚ö° Testent performance et accessibilit√©
4. üö´ Ne n√©cessitent PAS de coverage (pas du code m√©tier)

**Commande principale:**
```bash
cd 50_test
pytest -v
```

**R√©sultat attendu:**
- Local: 14-16 tests (Docker skip)
- Serveur: 35 tests (avec Docker)

---

**üìö Pour plus d'infos sur le coverage du code m√©tier:**
- `10_preprod/` ‚Üí Voir tests unitaires avec 96% coverage
- `20_prod/` ‚Üí Voir tests unitaires avec 100% coverage
- `README_COVERAGE.md` ‚Üí Guide complet du coverage
