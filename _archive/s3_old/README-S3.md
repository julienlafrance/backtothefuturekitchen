# ğŸ“¦ Guide d'utilisation du S3 Storage

## ğŸ¯ Vue d'ensemble

Ce projet utilise **Garage S3** pour le stockage des donnÃ©es. Le systÃ¨me dÃ©tecte automatiquement votre environnement rÃ©seau pour optimiser les performances.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 Fast (NVMe) - Stockage haute performance   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Endpoint local:  http://192.168.80.202:3910   â”‚
â”‚  Endpoint externe: https://s3fast.lafrance.io   â”‚
â”‚  RÃ©gion: garage-fast                            â”‚
â”‚  Bucket: mangetamain                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ DÃ©tection automatique du rÃ©seau

Le module `utils/utils_s3.py` dÃ©tecte automatiquement votre environnement :

- **RÃ©seau local** (`192.168.80.x` ou `192.168.0.x`) â†’ Utilise l'IP directe (ultra-rapide âš¡)
- **RÃ©seau externe** â†’ Utilise le reverse proxy HTTPS (sÃ©curisÃ© ğŸ”’)

## ğŸš€ DÃ©marrage rapide

### Import du module

Le module `utils/` est prÃ©sent dans chaque sous-projet (00_eda, 10_preprod, 20_prod) :

```python
# Import direct depuis le mÃªme dossier
from utils.utils_s3 import get_s3_client, get_duckdb_s3_connection
```

### 1. Connexion S3 classique

```python
from utils.utils_s3 import get_s3_client

# Connexion automatique
client, bucket = get_s3_client()

# Lister les fichiers
response = client.list_objects_v2(Bucket=bucket)
for obj in response.get('Contents', []):
    print(f"ğŸ“„ {obj['Key']} - {obj['Size']} bytes")
```

### 2. TÃ©lÃ©charger un fichier

```python
# TÃ©lÃ©charger un fichier spÃ©cifique
client.download_file(
    Bucket=bucket,
    Key='mangetamain.duckdb',
    Filename='data/mangetamain.duckdb'
)
```

### 3. Uploader un fichier

```python
# Uploader un fichier
client.upload_file(
    Filename='data/results.csv',
    Bucket=bucket,
    Key='results/analysis_results.csv'
)
```

## ğŸ¦† DuckDB avec S3 (RecommandÃ©)

### Connexion directe (sans tÃ©lÃ©chargement !)

```python
from utils.utils_s3 import get_duckdb_s3_connection

# Connexion DuckDB avec S3 configurÃ© automatiquement
con, bucket = get_duckdb_s3_connection()
```

### Query directe sur fichier CSV S3

```python
# Lire directement depuis S3 - AUCUN tÃ©lÃ©chargement !
df = con.execute(f"SELECT * FROM 's3://{bucket}/PP_recipes.csv' LIMIT 5").df()
print(df)
```

### AgrÃ©gations SQL complexes

```python
# Analyse directe sur S3 sans tÃ©lÃ©chargement
query = f"""
SELECT 
    calorie_level,
    COUNT(*) as nb_recipes,
    COUNT(DISTINCT id) as unique_recipes
FROM 's3://{bucket}/PP_recipes.csv'
GROUP BY calorie_level
ORDER BY calorie_level
"""

df = con.execute(query).df()
print(df)
```

**RÃ©sultat :**
```
 calorie_level  nb_recipes  unique_recipes
             0       69699           69699
             1       63255           63255
             2       45311           45311
```

## ğŸ³ Utilisation dans Docker

Les containers Docker accÃ¨dent aux credentials via un **volume read-only** :

```yaml
volumes:
  - ../96_keys:/app/../96_keys:ro       # Credentials (read-only)
  - ../10_preprod/utils:/app/utils:ro   # Module utils_s3
```

### Test dans un container

```bash
# Tester S3 dans preprod
docker exec -w /app mange_preprod uv run python -c "
from utils.utils_s3 import get_s3_client
client, bucket = get_s3_client(verbose=True)
print(f'âœ… {bucket}')
"

# Tester DuckDB dans prod
docker exec -w /app mange_prod uv run python -c "
from utils.utils_s3 import get_duckdb_s3_connection
con, bucket = get_duckdb_s3_connection()
df = con.execute(f'SELECT COUNT(*) as total FROM s3://{bucket}/PP_recipes.csv').df()
print(df)
"
```

### DÃ©marrage des containers

```bash
cd 30_docker

# Preprod (port 8500)
docker-compose -p mangetamain-preprod -f docker-compose-preprod.yml up -d

# Prod (port 8501)
docker-compose -p mangetamain-prod -f docker-compose-prod.yml up -d
```

Voir [README_DOCKER_S3.md](README_DOCKER_S3.md) pour plus de dÃ©tails sur Docker.

## âš™ï¸ Options avancÃ©es

### Mode verbose

Pour voir les informations de connexion :

```python
client, bucket = get_s3_client(verbose=True)
# ğŸ“ Credentials chargÃ©s depuis fichier local
# ğŸ”— S3 Endpoint: local (direct)
```

### Forcer l'endpoint externe

Utile pour tester ou contourner des problÃ¨mes rÃ©seau :

```python
client, bucket = get_s3_client(force_external=True)
```

### Utiliser un profil diffÃ©rent

Si vous avez plusieurs profils S3 configurÃ©s :

```python
client, bucket = get_s3_client(profile='autre_profil')
```

## ğŸ“Š Performances

| Environnement | Endpoint | Temps (1.4GB) | DÃ©bit |
|---------------|----------|---------------|-------|
| **VM locale** | Direct (3910) | ~2.7s | ~523 MB/s âš¡ |
| **VM via HTTPS** | Reverse proxy | ~13s | ~107 MB/s |
| **HÃ´te ixia** | Localhost | ~1.9s | ~718 MB/s ğŸš€ |
| **Docker** | HTTPS externe | ~13s | ~107 MB/s |

ğŸ’¡ **Astuce** : La dÃ©tection automatique utilise toujours le mode le plus rapide disponible !

## ğŸ”’ SÃ©curitÃ©

### Credentials

Les credentials sont stockÃ©s dans `96_keys/credentials` (ignorÃ© par git).

**Structure du fichier :**

```ini
[s3fast]
aws_access_key_id = GK4feb...
aws_secret_access_key = 50e63b...
endpoint_url = https://s3fast.lafrance.io
region = garage-fast
bucket = mangetamain
```

âš ï¸ **IMPORTANT** : Ne JAMAIS commit les credentials dans git !

### VÃ©rifier le .gitignore

Le dossier `96_keys/` doit Ãªtre dans `.gitignore` :

```bash
# Dans /home/dataia25/mangetamain/.gitignore
96_keys/
```

### Chargement des credentials

Le module `utils_s3.py` charge les credentials dans cet ordre :

1. **Variables d'environnement** (prioritaire, pour production distante)
   - `S3_ACCESS_KEY_ID`
   - `S3_SECRET_ACCESS_KEY`
   - `S3_BUCKET`
   - `S3_REGION` (optionnel)
   - `S3_ENDPOINT_URL` (optionnel)

2. **Fichier credentials** (pour dÃ©veloppement local et Docker)
   - Chemin : `../96_keys/credentials`
   - Format : INI avec section `[s3fast]`

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨me de connexion

```python
# Tester la connexion
from utils.utils_s3 import get_s3_client

try:
    client, bucket = get_s3_client(verbose=True)
    print(f"âœ… Connexion rÃ©ussie au bucket: {bucket}")
except Exception as e:
    print(f"âŒ Erreur: {e}")
```

### VÃ©rifier le rÃ©seau

```python
from utils.utils_s3 import is_on_local_network

if is_on_local_network():
    print("ğŸ“ Vous Ãªtes sur le rÃ©seau local")
else:
    print("ğŸŒ Vous Ãªtes sur un rÃ©seau externe")
```

### Credentials introuvables

Si vous voyez l'erreur `Credentials introuvable`, vÃ©rifiez :

```bash
# Le fichier doit exister ici :
ls -la 96_keys/credentials

# Si absent, contactez l'administrateur
```

### Test complet dans uv

```bash
cd 10_preprod
uv run python -c "
from utils.utils_s3 import get_s3_client, get_duckdb_s3_connection

# Test S3
client, bucket = get_s3_client(verbose=True)
print(f'âœ… S3 : {bucket}')

# Test DuckDB
con, bucket = get_duckdb_s3_connection()
df = con.execute(f'SELECT COUNT(*) FROM s3://{bucket}/PP_recipes.csv').df()
print(f'âœ… DuckDB : {df.iloc[0,0]} recettes')
"
```

## ğŸ“š Exemples complets

### Exemple 1 : Analyse DuckDB sur CSV S3

```python
from utils.utils_s3 import get_duckdb_s3_connection

# Connexion directe S3
con, bucket = get_duckdb_s3_connection()

# Analyse directe sans tÃ©lÃ©chargement
query = f"""
SELECT 
    calorie_level,
    COUNT(*) as recipes_count,
    COUNT(DISTINCT id) as unique_recipes
FROM 's3://{bucket}/PP_recipes.csv'
GROUP BY calorie_level
ORDER BY recipes_count DESC
"""

df = con.execute(query).df()
print("ğŸ“Š Analyse des recettes par niveau calorique:")
print(df)
```

### Exemple 2 : Comparaison de fichiers S3

```python
# Comparer deux datasets directement sur S3
query = f"""
SELECT 
    'recipes' as source,
    COUNT(*) as count
FROM 's3://{bucket}/PP_recipes.csv'

UNION ALL

SELECT 
    'interactions' as source,
    COUNT(*) as count
FROM 's3://{bucket}/PP_user_interactions.csv'
"""

df = con.execute(query).df()
print("ğŸ“ˆ Comparaison des datasets:")
print(df)
```

### Exemple 3 : Export de rÃ©sultats vers S3

```python
from utils.utils_s3 import get_s3_client, get_duckdb_s3_connection
import pandas as pd

# Analyse avec DuckDB
con, bucket = get_duckdb_s3_connection()
df_results = con.execute(f"SELECT * FROM 's3://{bucket}/PP_recipes.csv' LIMIT 100").df()

# Sauvegarder localement
df_results.to_csv('analysis_results.csv', index=False)

# Upload vers S3
client, bucket = get_s3_client()
client.upload_file('analysis_results.csv', bucket, 'results/analysis_results.csv')
print("âœ… RÃ©sultats uploadÃ©s sur S3")
```

## ğŸ“¦ Structure du projet

```
mangetamain/
â”œâ”€â”€ 96_keys/                    â† Credentials (ignorÃ© par git)
â”‚   â””â”€â”€ credentials
â”œâ”€â”€ utils/                      â† Module partagÃ© (rÃ©fÃ©rence)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ utils_s3.py
â”œâ”€â”€ 00_eda/
â”‚   â””â”€â”€ utils/                  â† Copie locale
â”œâ”€â”€ 10_preprod/
â”‚   â””â”€â”€ utils/                  â† Copie locale
â”œâ”€â”€ 20_prod/
â”‚   â””â”€â”€ utils/                  â† Copie locale
â””â”€â”€ 30_docker/
    â”œâ”€â”€ docker-compose-preprod.yml
    â””â”€â”€ docker-compose-prod.yml
```

**Note** : Le dossier `utils/` est copiÃ© dans chaque sous-projet pour faciliter le dÃ©ploiement Docker.

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- VÃ©rifiez d'abord ce README
- Testez avec `verbose=True` pour plus d'informations
- Consultez [README_DOCKER_S3.md](README_DOCKER_S3.md) pour Docker
- Contactez l'Ã©quipe infrastructure pour les problÃ¨mes de credentials

---

**DerniÃ¨re mise Ã  jour** : 2025-10-08  
**Responsable** : Infrastructure Team  
**Tests** : âœ… ValidÃ© sur preprod et prod Docker
