# Guide : Convertir un Notebook Jupyter vers Streamlit avec Minimum d'Effort

## üéØ Objectif
Cr√©er un syst√®me automatisable pour int√©grer facilement des analyses de notebooks dans l'application Streamlit.

## üìã Structure standardis√©e pour les modules

### 1. Template de base pour vos modules Python

Cr√©ez vos fichiers dans `visualization/` avec cette structure :

```python
# <M√âTADONN√âES>
# Nom: mon_analyse.py
# Description: [Description de votre analyse]
# Auteur: [Votre nom]
# Date: [Date de cr√©ation]
# Version: 1.0
# Cat√©gorie: Analyse exploratoire
# </M√âTADONN√âES>

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
# <IMPORTS>
# Ajoutez vos imports sp√©cifiques ici
# import numpy as np
# import seaborn as sns
# </IMPORTS>

def render_analysis(conn):
    """
    Fonction principale qui sera automatiquement d√©tect√©e et int√©gr√©e.
    
    Args:
        conn: Connexion DuckDB
    """
    
    # <TITRE>
    st.subheader("üìä Titre de votre analyse")
    # </TITRE>
    
    # <DESCRIPTION>
    st.markdown("""
    Description de votre analyse en markdown.
    Peut √™tre sur plusieurs lignes.
    
    **Contexte :** Expliquez le contexte de l'analyse
    **Objectif :** Que cherchez-vous √† d√©montrer ?
    """)
    # </DESCRIPTION>
    
    # <REQU√äTE_SQL>
    try:
        data = conn.execute("""
            -- Votre requ√™te SQL principale
            SELECT * FROM votre_table 
            WHERE condition IS NOT NULL
            LIMIT 1000
        """).fetchdf()
    # </REQU√äTE_SQL>
        
        # <TRAITEMENT>
        # Votre code de traitement des donn√©es
        # data['nouvelle_colonne'] = data['colonne1'] * data['colonne2']
        # data_filtered = data[data['colonne'] > seuil]
        # </TRAITEMENT>
        
        # <GRAPHIQUE_PRINCIPAL>
        fig = px.scatter(data, 
                        x='col1', 
                        y='col2', 
                        title="Mon graphique principal",
                        hover_data=['col3'])
        st.plotly_chart(fig, use_container_width=True)
        # </GRAPHIQUE_PRINCIPAL>
        
        # <GRAPHIQUES_SECONDAIRES>
        # Graphiques additionnels si n√©cessaire
        # fig2 = px.histogram(data, x='col1')
        # st.plotly_chart(fig2, use_container_width=True)
        # </GRAPHIQUES_SECONDAIRES>
        
        # <STATISTIQUES>
        # M√©triques et statistiques descriptives
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("M√©trique 1", f"{data['col1'].mean():.2f}")
        with col2:
            st.metric("M√©trique 2", f"{data['col2'].sum():,}")
        with col3:
            st.metric("M√©trique 3", f"{len(data)}")
        # </STATISTIQUES>
        
        # <INTERPR√âTATION>
        st.markdown("""
        **R√©sultats principaux :**
        - Point cl√© 1
        - Point cl√© 2
        - Point cl√© 3
        
        **Conclusions :**
        Vos conclusions d√©taill√©es ici.
        """)
        # </INTERPR√âTATION>
        
        # <DONN√âES_BRUTES>
        # Optionnel : affichage des donn√©es brutes
        with st.expander("Voir les donn√©es brutes"):
            st.dataframe(data.head(100))
        # </DONN√âES_BRUTES>
        
    except Exception as e:
        st.error(f"Erreur dans l'analyse : {e}")


# <MODULE_INFO>
MODULE_INFO = {
    "name": "Mon Analyse",
    "description": "Description courte pour l'interface",
    "category": "Analyse exploratoire",  # Analyse exploratoire, ML, Statistiques, Visualisation
    "author": "Votre nom",
    "version": "1.0",
    "tags": ["tag1", "tag2"],  # Tags pour le filtrage
    "data_sources": ["table1", "table2"],  # Tables utilis√©es
    "created_date": "2024-01-01",
    "last_modified": "2024-01-01"
}
# </MODULE_INFO>
```

## ü§ñ Syst√®me d'auto-int√©gration

### 2. Fonction de d√©couverte automatique

Ajoutez dans `main.py` cette fonction qui d√©couvre automatiquement tous vos modules :

```python
import importlib
import os
from pathlib import Path

def parse_xml_tags_from_file(file_path):
    """Parse les balises XML depuis le fichier source."""
    import re
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Parser les diff√©rentes sections
    sections = {}
    
    # M√©tadonn√©es du header
    metadata_match = re.search(r'# <M√âTADONN√âES>(.*?)# </M√âTADONN√âES>', content, re.DOTALL)
    if metadata_match:
        metadata_lines = metadata_match.group(1).strip().split('\n')
        metadata = {}
        for line in metadata_lines:
            if ':' in line and line.startswith('#'):
                key, value = line.replace('#', '').strip().split(':', 1)
                metadata[key.strip()] = value.strip()
        sections['metadata'] = metadata
    
    # Autres sections importantes
    for tag in ['IMPORTS', 'REQU√äTE_SQL', 'TRAITEMENT', 'GRAPHIQUE_PRINCIPAL', 'INTERPR√âTATION']:
        pattern = f'# <{tag}>(.*?)# </{tag}>'
        match = re.search(pattern, content, re.DOTALL)
        if match:
            sections[tag.lower()] = match.group(1).strip()
    
    return sections

def discover_custom_modules():
    """D√©couvre automatiquement tous les modules d'analyse avec parsing XML."""
    modules = []
    viz_dir = Path("visualization")
    
    for file_path in viz_dir.glob("*.py"):
        if file_path.name.startswith("__") or file_path.name == "custom_charts.py":
            continue
            
        module_name = file_path.stem
        try:
            # Parse les balises XML du fichier source
            xml_sections = parse_xml_tags_from_file(file_path)
            
            # Import dynamique
            spec = importlib.util.spec_from_file_location(module_name, file_path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            # V√©rifier que le module a les fonctions requises
            if hasattr(module, 'render_analysis') and hasattr(module, 'MODULE_INFO'):
                module_info = module.MODULE_INFO.copy()
                
                # Enrichir avec les infos du parsing XML si disponibles
                if 'metadata' in xml_sections:
                    metadata = xml_sections['metadata']
                    if 'Description' in metadata:
                        module_info['file_description'] = metadata['Description']
                    if 'Date' in metadata:
                        module_info['creation_date'] = metadata['Date']
                
                modules.append({
                    'module': module,
                    'info': module_info,
                    'render': module.render_analysis,
                    'xml_sections': xml_sections,
                    'file_path': str(file_path)
                })
        except Exception as e:
            st.sidebar.error(f"Erreur lors du chargement de {module_name}: {e}")
    
    return modules

def create_auto_custom_visualizations(conn):
    """Interface automatique pour tous les modules d√©couverts."""
    st.subheader("ü§ñ Analyses automatiquement d√©tect√©es")
    
    modules = discover_custom_modules()
    
    if not modules:
        st.warning("Aucun module d'analyse trouv√© dans visualization/")
        return
    
    # S√©lecteur de module
    module_names = [f"{m['info']['name']} ({m['info']['category']})" for m in modules]
    selected_idx = st.selectbox("Choisir une analyse:", range(len(modules)), 
                               format_func=lambda x: module_names[x])
    
    if selected_idx is not None:
        selected_module = modules[selected_idx]
        
        # Afficher les m√©tadonn√©es
        with st.expander("‚ÑπÔ∏è Informations sur cette analyse"):
            st.write(f"**Auteur :** {selected_module['info']['author']}")
            st.write(f"**Version :** {selected_module['info']['version']}")
            st.write(f"**Description :** {selected_module['info']['description']}")
        
        # Ex√©cuter l'analyse
        selected_module['render'](conn)
```

## üîÑ Workflow de conversion d'un notebook

### 3. √âtapes simplifi√©es

1. **Copiez votre notebook** dans le dossier `notebooks/` (optionnel, pour archivage)

2. **Cr√©ez un nouveau fichier** : `visualization/mon_analyse_[date].py`

3. **Copiez le template** ci-dessus et remplissez :
   - Les m√©tadonn√©es en haut
   - Votre requ√™te SQL dans la section DONN√âES
   - Votre code de traitement
   - Votre graphique (adaptez pour Plotly si n√©cessaire)
   - Vos textes explicatifs

4. **Conversion automatique des √©l√©ments** :

| Notebook | Streamlit | Balise XML |
|----------|-----------|------------|
| `# Titre markdown` | `st.subheader("Titre")` | `<TITRE>` |
| `print(variable)` | `st.write(variable)` | `<STATISTIQUES>` |
| `df.head()` | `st.dataframe(df.head())` | `<DONN√âES_BRUTES>` |
| `plt.show()` | `st.plotly_chart(fig)` | `<GRAPHIQUE_PRINCIPAL>` |
| Cellule markdown | `st.markdown(""")` | `<INTERPR√âTATION>` |

## üè∑Ô∏è Avantages des balises XML

### **Pour vous (d√©veloppeur) :**
- **Structure claire** : Chaque section est bien d√©limit√©e
- **Navigation rapide** : Facile de retrouver une section sp√©cifique
- **R√©utilisabilit√©** : Template coh√©rent pour tous vos modules
- **Documentation automatique** : Les balises servent de documentation

### **Pour un robot/parser :**
- **Parsing fiable** : Structure pr√©visible avec regex simples
- **M√©tadonn√©es extraites** : Auteur, date, description automatiquement r√©cup√©r√©s
- **Sections identifi√©es** : Code, requ√™tes SQL, graphiques s√©par√©s
- **Validation automatique** : V√©rifier que toutes les sections requises sont pr√©sentes

### **Exemples d'utilisation automatique :**

```python
# G√©n√©rer automatiquement une documentation
def generate_module_doc(file_path):
    sections = parse_xml_tags_from_file(file_path)
    doc = f"""# {sections['metadata']['Nom']}
    
**Auteur :** {sections['metadata']['Auteur']}
**Date :** {sections['metadata']['Date']}
    
## Description
{sections['metadata']['Description']}
    
## Requ√™tes SQL utilis√©es
```sql
{sections['requ√™te_sql']}
```
    """
    return doc

# Extraire automatiquement les d√©pendances
def extract_dependencies(file_path):
    sections = parse_xml_tags_from_file(file_path)
    imports = sections.get('imports', '')
    # Parser les imports pour cr√©er requirements.txt
    
# Valider la structure
def validate_module_structure(file_path):
    sections = parse_xml_tags_from_file(file_path)
    required_sections = ['M√âTADONN√âES', 'REQU√äTE_SQL', 'GRAPHIQUE_PRINCIPAL']
    missing = [s for s in required_sections if s.lower() not in sections]
    return len(missing) == 0, missing
```

## üìÅ Structure de fichiers recommand√©e

```
mangetamain_analytics/
‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ custom_charts.py          # Fonctions utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ analyse_ratings_2024.py   # Votre analyse 1
‚îÇ   ‚îú‚îÄ‚îÄ analyse_temporelle_2024.py # Votre analyse 2
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ notebooks/                    # Archive des notebooks originaux
‚îÇ   ‚îú‚îÄ‚îÄ analyse_ratings.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ main.py
```

## üöÄ Int√©gration dans main.py

### 4. Modification minimale de main.py

Remplacez la fonction `create_custom_visualizations` par `create_auto_custom_visualizations` :

```python
# Dans les tabs
with tab6:
    create_auto_custom_visualizations(conn)  # Au lieu de create_custom_visualizations
```

## ‚úÖ Checklist de validation

Avant de d√©ployer un nouveau module :

- [ ] Le fichier respecte le template
- [ ] `MODULE_INFO` est d√©fini
- [ ] `render_analysis(conn)` existe
- [ ] Pas d'erreur lors de l'import
- [ ] Les graphiques s'affichent correctement
- [ ] Les textes explicatifs sont pr√©sents

## üéÅ Avantages de cette approche

1. **Z√©ro modification de main.py** pour ajouter une nouvelle analyse
2. **Auto-d√©tection** de tous les modules
3. **M√©tadonn√©es standardis√©es** pour la documentation
4. **Gestion d'erreurs** automatique
5. **Archivage** des notebooks originaux
6. **Structure coh√©rente** pour tous les modules

## üîß Utilisation

1. **Pour ajouter une nouvelle analyse** : Cr√©ez un fichier avec le template
2. **Pour retirer une analyse** : Renommez le fichier avec un `_` au d√©but
3. **Pour modifier une analyse** : √âditez directement le fichier Python
4. **Pour versionner** : Utilisez des suffixes de date dans les noms

Cette approche permet d'industrialiser facilement la cr√©ation d'analyses tout en gardant la flexibilit√© du d√©veloppement individuel.