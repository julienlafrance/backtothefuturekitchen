"""Module d'analyse des ratings/notes temporelles.

Ce module contient les analyses de l'Ã©volution des ratings dans le temps,
incluant les analyses de tendances, saisonnalitÃ© et effet weekend.
Converti depuis rating_analysis_integration.py avec thÃ¨me Back to the Kitchen.
"""

import streamlit as st
import pandas as pd
import polars as pl
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.stats import kendalltau, linregress, f_oneway, kruskal
import statsmodels.api as sm

# Import du thÃ¨me graphique
from utils import chart_theme
from utils.color_theme import ColorTheme

# Import des utilitaires de chargement avec cache
from data.cached_loaders import (
    get_ratings_longterm as load_ratings_for_longterm_analysis,
)

# Import direct sans cache (utilisÃ© rarement)
from mangetamain_data_utils.data_utils_ratings import load_clean_interactions


def weighted_spearman(x, y, w):
    """Calcule le coefficient de corrÃ©lation de Spearman pondÃ©rÃ©.

    Args:
        x: Variable X
        y: Variable Y
        w: Poids pour chaque observation

    Returns:
        float: Coefficient de Spearman pondÃ©rÃ©
    """
    # Rang pondÃ©rÃ©
    rank_x = pd.Series(x).rank(method="average").values
    rank_y = pd.Series(y).rank(method="average").values

    # CorrÃ©lation pondÃ©rÃ©e entre les rangs
    cov_matrix = np.cov(rank_x, rank_y, aweights=w)
    cov_xy = cov_matrix[0, 1]
    var_x = np.cov(rank_x, aweights=w)
    var_y = np.cov(rank_y, aweights=w)

    # Gestion du cas oÃ¹ np.cov retourne un scalaire
    if np.ndim(var_x) == 0:
        std_x = np.sqrt(var_x)
    else:
        std_x = np.sqrt(var_x[0, 0])

    if np.ndim(var_y) == 0:
        std_y = np.sqrt(var_y)
    else:
        std_y = np.sqrt(var_y[0, 0])

    weighted_corr = cov_xy / (std_x * std_y)
    return weighted_corr


def analyse_ratings_validation_ponderee() -> None:
    """Analyse 1: Validation mÃ©thodologique - Tests pondÃ©rÃ©s vs non-pondÃ©rÃ©s."""
    st.markdown(
        """
        Comparaison des mÃ©thodes **pondÃ©rÃ©es** vs **non-pondÃ©rÃ©es** pour analyser
        l'Ã©volution des ratings dans le temps. Cette analyse dÃ©montre l'importance
        de la pondÃ©ration par le volume d'interactions.
        """
    )

    # Chargement des donnÃ©es
    with st.spinner("Chargement des statistiques mensuelles..."):
        monthly_stats, metadata = load_ratings_for_longterm_analysis(
            min_interactions=100, return_metadata=True, verbose=False
        )

    if monthly_stats.empty:
        st.error("âŒ Aucune donnÃ©e disponible")
        return

    # PrÃ©paration du DataFrame
    monthly_df = monthly_stats.copy()
    monthly_df["date"] = pd.to_datetime(monthly_df["date"])
    monthly_df = monthly_df.sort_values("date")
    monthly_df["mean_rating"] = pd.to_numeric(
        monthly_df["mean_rating"], errors="coerce"
    )
    monthly_df["std_rating"] = pd.to_numeric(
        monthly_df.get("std_rating", 0), errors="coerce"
    ).fillna(0)
    monthly_df["n_interactions"] = pd.to_numeric(
        monthly_df["n_interactions"], errors="coerce"
    ).fillna(0)
    monthly_df = monthly_df.dropna(subset=["mean_rating"])

    # Variables pour tests statistiques
    monthly_sorted = monthly_df.sort_values("date")
    time_index = range(len(monthly_sorted))
    ratings = monthly_sorted["mean_rating"].values
    weights = np.sqrt(monthly_df["n_interactions"].values)
    weights_normalized = weights / weights.sum()

    # Analyse de l'hÃ©tÃ©rogÃ©nÃ©itÃ©
    cv_volumes = np.std(monthly_df["n_interactions"]) / np.mean(
        monthly_df["n_interactions"]
    )
    # noqa: F841
    # CrÃ©ation du graphique avec 4 subplots
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=(
            "Distribution des volumes mensuels",
            "Ã‰volution des poids dans le temps",
            "Ratings pondÃ©rÃ©s par volume",
            "Variance des ratings",
        ),
        specs=[
            [{"type": "histogram"}, {"type": "scatter"}],
            [{"type": "scatter"}, {"type": "bar"}],
        ],
    )

    # (1) Distribution des volumes (histogram)
    fig.add_trace(
        go.Histogram(
            x=monthly_df["n_interactions"],
            nbinsx=20,
            marker=dict(
                color=ColorTheme.CHART_COLORS[0],
                opacity=0.7,
                line=dict(width=0),  # Pas de contour
            ),
            showlegend=False,
        ),
        row=1,
        col=1,
    )

    # (2) Poids calculÃ©s dans le temps
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=weights_normalized,
            mode="lines+markers",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=2),
            marker=dict(size=4),
            name="Poids normalisÃ©s",
            showlegend=True,
        ),
        row=1,
        col=2,
    )

    # (3) Ratings avec taille proportionnelle au poids
    sizes = weights_normalized * 1000

    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=monthly_df["mean_rating"],
            mode="markers",
            marker=dict(
                size=sizes * 2,  # Points beaucoup plus gros
                color=monthly_df["n_interactions"],
                colorscale="YlOrRd",  # Colorscale Plotly: Jaune â†’ Orange â†’ Rouge
                opacity=0.7,
                line=dict(color=ColorTheme.TEXT_PRIMARY, width=0.5),
                colorbar=dict(
                    title=dict(
                        text="Volume", font=dict(color=ColorTheme.TEXT_PRIMARY, size=12)
                    ),
                    tickfont=dict(color=ColorTheme.TEXT_PRIMARY, size=10),
                    x=0.46,  # RepositionnÃ© entre les 2 colonnes
                    len=0.35,
                    y=0.23,
                    yanchor="middle",
                ),
            ),
            showlegend=False,
        ),
        row=2,
        col=1,
    )

    # (4) Comparaison variance pondÃ©rÃ©e vs non-pondÃ©rÃ©e
    var_unweighted = np.var(monthly_df["mean_rating"])
    var_weighted = np.average(
        (
            monthly_df["mean_rating"]
            - np.average(monthly_df["mean_rating"], weights=weights)
        )
        ** 2,
        weights=weights,
    )

    fig.add_trace(
        go.Bar(
            x=["Non pondÃ©rÃ©e", "PondÃ©rÃ©e"],
            y=[var_unweighted, var_weighted],
            marker=dict(
                color=[ColorTheme.CHART_COLORS[2], ColorTheme.CHART_COLORS[0]],
                opacity=0.8,
                line=dict(width=0),  # Pas de contour
            ),
            text=[f"{var_unweighted:.4f}", f"{var_weighted:.4f}"],
            textposition="outside",
            textfont=dict(size=12, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=2,
        col=2,
    )

    # Axes
    fig.update_xaxes(title_text="Nombre d'interactions", row=1, col=1)
    fig.update_yaxes(title_text="FrÃ©quence (log)", type="log", row=1, col=1)

    fig.update_xaxes(title_text="Date", row=1, col=2)
    fig.update_yaxes(title_text="Poids normalisÃ©", row=1, col=2)

    fig.update_xaxes(title_text="Date", row=2, col=1)
    fig.update_yaxes(title_text="Rating moyen", row=2, col=1)

    fig.update_yaxes(title_text="Variance", row=2, col=2)

    # Mise en forme
    fig.update_layout(
        height=900,
        showlegend=True,
        title_text="Impact de la pondÃ©ration par volume sur l'analyse",
        bargap=0,  # Supprime l'espace entre les barres de l'histogramme
    )

    # Application du thÃ¨me "Back to the Kitchen"
    chart_theme.apply_subplot_theme(fig, num_rows=2, num_cols=2)

    st.plotly_chart(fig, use_container_width=True)

    # Tests statistiques
    tau, p_value_kendall = kendalltau(time_index, ratings)
    slope, intercept, r_value, p_value_reg, std_err = linregress(time_index, ratings)

    # Tests pondÃ©rÃ©s
    x = np.array(time_index)
    y = ratings
    w = weights

    # RÃ©gression pondÃ©rÃ©e (WLS)
    X_const = sm.add_constant(x)
    wls_model = sm.WLS(y, X_const, weights=w)
    wls_result = wls_model.fit()
    y_pred_weighted = wls_result.predict(X_const)
    y_mean_weighted = np.average(y, weights=w)
    r2_weighted = 1 - np.average((y - y_pred_weighted) ** 2, weights=w) / np.average(
        (y - y_mean_weighted) ** 2, weights=w
    )

    bias_slope = (
        abs(wls_result.params[1] - slope) / abs(slope) * 100 if slope != 0 else 0
    )

    # MÃ©triques
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("CV Volumes", f"{cv_volumes:.2f}")
    with col2:
        st.metric("Biais pente", f"{bias_slope:.1f}%")
    with col3:  # noqa: F841
        st.metric("RÂ² pondÃ©rÃ©", f"{r2_weighted:.4f}")
    with col4:
        st.metric("P-value WLS", f"{wls_result.pvalues[1]:.4f}")

    # InterprÃ©tation
    st.info(
        f"""
    ğŸ’¡ **InterprÃ©tation statistique**

    L'analyse mÃ©thodologique rÃ©vÃ¨le une **hÃ©tÃ©rogÃ©nÃ©itÃ© extrÃªme des volumes d'interactions** mensuels
    (Coefficient de variation = **{cv_volumes:.2f}**), ce qui rend les tests statistiques standards **non fiables**.
    Les tests non-pondÃ©rÃ©s s'avÃ¨rent **fortement biaisÃ©s** (biais de pente de **+{bias_slope:.1f}%**), car ils donnent une importance
    disproportionnÃ©e aux pÃ©riodes de **trÃ¨s forte activitÃ©** (comme 2008-2009), Ã©crasant l'influence des autres pÃ©riodes.
    L'utilisation de **mÃ©thodes pondÃ©rÃ©es** (comme la rÃ©gression WLS et le Spearman pondÃ©rÃ©) est donc **indispensable** pour corriger
    ce biais et obtenir une **interprÃ©tation juste et robuste** des tendances rÃ©elles du comportement utilisateur.
    """
    )


def analyse_ratings_tendance_temporelle() -> None:
    """Analyse 2: Tendance temporelle des ratings (MÃ©thodes pondÃ©rÃ©es)."""
    st.markdown(
        """
        Analyse de l'Ã©volution des ratings dans le temps avec **rÃ©gression WLS pondÃ©rÃ©e**.
        Examine la stabilitÃ©, le volume d'interactions et la corrÃ©lation volume-qualitÃ©.
        """
    )

    # Chargement des donnÃ©es
    with st.spinner("Chargement des statistiques mensuelles..."):
        monthly_stats, _ = load_ratings_for_longterm_analysis(
            min_interactions=100, return_metadata=True
        )

    if monthly_stats.empty:
        st.error("âŒ Aucune donnÃ©e disponible")
        return

    # PrÃ©paration du DataFrame
    monthly_df = monthly_stats.copy()
    monthly_df["date"] = pd.to_datetime(monthly_df["date"])
    monthly_df = monthly_df.sort_values("date")
    monthly_df = monthly_df.dropna(subset=["mean_rating"])

    # Variables pour tests
    ratings = monthly_df["mean_rating"].values
    volumes = monthly_df["n_interactions"].values
    weights = np.sqrt(volumes)
    weights_normalized = weights / weights.sum()

    # Calcul tendance pondÃ©rÃ©e
    X_trend = np.arange(len(monthly_df))
    X_const_trend = sm.add_constant(X_trend)  # noqa: F841
    wls_trend = sm.WLS(ratings, X_const_trend, weights=weights)
    wls_trend_result = wls_trend.fit()
    trend_line_weighted = wls_trend_result.predict(X_const_trend)

    # RÂ² pondÃ©rÃ©
    y_mean_weighted = np.average(ratings, weights=weights)
    r2_weighted = 1 - np.average(
        (ratings - trend_line_weighted) ** 2, weights=weights
    ) / np.average((ratings - y_mean_weighted) ** 2, weights=weights)

    # Ã‰cart-type pondÃ©rÃ©
    weighted_std = np.sqrt(
        np.average(
            (ratings - np.average(ratings, weights=weights)) ** 2, weights=weights
        )
    )

    # RÃ©gression volume vs qualitÃ©
    X_vol_const = sm.add_constant(volumes)
    wls_vol = sm.WLS(ratings, X_vol_const, weights=weights)
    wls_vol_result = wls_vol.fit()
    vol_pred = wls_vol_result.predict(X_vol_const)

    # CrÃ©ation du graphique avec 4 subplots
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=(
            "Ã‰volution des ratings - Tendance pondÃ©rÃ©e",
            "Volume d'interactions",
            "StabilitÃ© des ratings",
            "CorrÃ©lation volume-qualitÃ©",
        ),
    )

    # (1) Tendance des ratings
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=ratings,
            mode="lines+markers",
            line=dict(color=ColorTheme.CHART_COLORS[3], width=2),
            marker=dict(size=4),
            name="Rating moyen",
            showlegend=True,
        ),
        row=1,
        col=1,
    )

    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=trend_line_weighted,
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=2, dash="dash"),
            name=f"Tendance ({wls_trend_result.params[1]:.4f}/mois)",
            showlegend=True,
        ),
        row=1,
        col=1,
    )

    # (2) Volume d'interactions
    sizes = weights_normalized * 500
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=volumes,
            mode="markers",
            marker=dict(
                size=sizes * 2,  # Points beaucoup plus gros
                color=ColorTheme.CHART_COLORS[0],
                opacity=0.7,
                line=dict(width=0),  # Pas de contour
            ),
            showlegend=False,
        ),
        row=1,
        col=2,
    )

    # (3) StabilitÃ© (Ã©cart-type)
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=monthly_df["std_rating"],
            mode="lines+markers",
            line=dict(color=ColorTheme.CHART_COLORS[1], width=2),
            marker=dict(size=4),
            name="Ã‰cart-type brut",
            showlegend=True,
        ),
        row=2,
        col=1,
    )

    fig.add_trace(
        go.Scatter(
            x=[monthly_df["date"].min(), monthly_df["date"].max()],
            y=[weighted_std, weighted_std],
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=2, dash="dash"),
            name=f"Ã‰cart-type pondÃ©rÃ© ({weighted_std:.3f})",
            showlegend=True,
        ),
        row=2,
        col=1,
    )

    # (4) Relation volume vs qualitÃ©
    sizes_scatter = weights_normalized * 300
    fig.add_trace(
        go.Scatter(
            x=volumes,
            y=ratings,
            mode="markers",
            marker=dict(
                size=sizes_scatter * 2,  # Points plus gros
                color=weights_normalized,
                colorscale="YlOrRd",  # Colorscale charte: Jaune â†’ Orange â†’ Rouge
                opacity=0.7,
                line=dict(width=0),  # Pas de contour
                colorbar=dict(title="Poids", x=1.0, len=0.4, y=0.25),
            ),
            showlegend=False,
        ),
        row=2,
        col=2,
    )

    # Ligne de rÃ©gression
    fig.add_trace(
        go.Scatter(
            x=volumes,
            y=vol_pred,
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=2, dash="dash"),
            name="RÃ©gression pondÃ©rÃ©e",
            showlegend=True,
        ),
        row=2,
        col=2,
    )

    # Axes
    fig.update_yaxes(title_text="Rating moyen", row=1, col=1)
    fig.update_yaxes(title_text="Nombre d'interactions", row=1, col=2)
    fig.update_xaxes(title_text="Date", row=2, col=1)
    fig.update_yaxes(title_text="Ã‰cart-type", row=2, col=1)
    fig.update_xaxes(title_text="Nombre d'interactions", row=2, col=2)
    fig.update_yaxes(title_text="Rating moyen", row=2, col=2)

    # Mise en forme
    fig.update_layout(
        height=900,
        showlegend=True,
        title_text=f"Analyse Temporelle - Pente: {wls_trend_result.params[1]:+.4f}/mois",
    )

    # Application du thÃ¨me
    chart_theme.apply_subplot_theme(fig, num_rows=2, num_cols=2)

    st.plotly_chart(fig, use_container_width=True)

    # CorrÃ©lation pondÃ©rÃ©e
    vol_qual_weighted = weighted_spearman(volumes, ratings, weights)

    # MÃ©triques
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Pente pondÃ©rÃ©e", f"{wls_trend_result.params[1]:.6f} pts/mois")
    with col2:
        st.metric("RÂ² pondÃ©rÃ©", f"{r2_weighted:.4f}")
    with col3:
        st.metric("P-value", f"{wls_trend_result.pvalues[1]:.4f}")
    with col4:
        st.metric("Corr. volume-qualitÃ©", f"{vol_qual_weighted:.3f}")

    # InterprÃ©tation
    st.info(
        f"""
    ğŸ’¡ **InterprÃ©tation statistique**

    L'analyse temporelle pondÃ©rÃ©e rÃ©vÃ¨le une **stabilitÃ© remarquable des notes moyennes** sur le long terme,
    contredisant l'intuition d'une Ã©ventuelle dÃ©gradation ou amÃ©lioration.
    La tendance observÃ©e est **statistiquement non significative** (pente annuelle = **{wls_trend_result.params[1] * 12:.4f} points/an**,
    p-value = **{wls_trend_result.pvalues[1]:.2f}**). Le RÂ² pondÃ©rÃ© de **{r2_weighted:.3f}** confirme que le temps n'explique quasiment
    **aucune variance** dans les notes. On observe Ã©galement une **faible corrÃ©lation nÃ©gative** entre le **volume** d'interactions et
    la **qualitÃ©** perÃ§ue (Ï = **{vol_qual_weighted:.3f}**), suggÃ©rant que les mois de **plus forte activitÃ©** sont associÃ©s Ã  des
    **notes moyennes trÃ¨s lÃ©gÃ¨rement plus basses**. Cette stabilitÃ© globale confirme que le **comportement de notation des utilisateurs**
    est **extrÃªmement constant** depuis 2005.
    """
    )


def analyse_ratings_distribution() -> None:
    """Analyse 3: Ã‰volution dÃ©taillÃ©e et corrÃ©lations (bandes de confiance)."""
    st.markdown(
        """
        Analyse dÃ©taillÃ©e de l'Ã©volution des ratings avec **bandes de confiance**.
        Vue d'ensemble et vue zoomÃ©e de la stabilitÃ© temporelle.
        """
    )

    # Chargement des donnÃ©es
    with st.spinner("Chargement des statistiques mensuelles..."):
        monthly_stats, _ = load_ratings_for_longterm_analysis(
            min_interactions=100, return_metadata=True
        )

    if monthly_stats.empty:
        st.error("âŒ Aucune donnÃ©e disponible")
        return

    # PrÃ©paration du DataFrame
    monthly_df = monthly_stats.copy()
    monthly_df["date"] = pd.to_datetime(monthly_df["date"])
    monthly_df = monthly_df.sort_values("date")
    monthly_df = monthly_df.dropna(subset=["mean_rating"])

    # Variables pour tests
    ratings = monthly_df["mean_rating"].values
    volumes = monthly_df["n_interactions"].values
    weights = np.sqrt(volumes)
    weights_normalized = weights / weights.sum()

    # --- CALCUL TENDANCE ET IC ---
    mean_rating_weighted = np.average(ratings, weights=weights)
    std_rating_weighted = np.sqrt(
        np.average((ratings - mean_rating_weighted) ** 2, weights=weights)
    )

    # IC 95%
    upper_bound_weighted = mean_rating_weighted + 1.96 * std_rating_weighted / np.sqrt(
        np.sum(weights)
    )
    lower_bound_weighted = mean_rating_weighted - 1.96 * std_rating_weighted / np.sqrt(
        np.sum(weights)
    )

    # Tendance (WLS)
    X_trend = np.arange(len(monthly_df))
    X_const_trend = sm.add_constant(X_trend)
    wls_trend = sm.WLS(ratings, X_const_trend, weights=weights)
    wls_trend_result = wls_trend.fit()
    trend_weighted_detailed = wls_trend_result.predict(X_const_trend)

    # CorrÃ©lation volume-qualitÃ©
    X_vol_detailed = sm.add_constant(volumes)
    wls_vol_detailed = sm.WLS(ratings, X_vol_detailed, weights=weights)
    wls_vol_detailed_result = wls_vol_detailed.fit()
    vol_pred_detailed = wls_vol_detailed_result.predict(X_vol_detailed)
    vol_qual_weighted = weighted_spearman(volumes, ratings, weights)

    # CrÃ©ation du graphique avec 3 subplots
    fig = make_subplots(
        rows=3,
        cols=1,
        subplot_titles=(
            "Ã‰volution temporelle - Vue d'ensemble",
            "Ã‰volution temporelle - Vue zoomÃ©e",
            "CorrÃ©lation volume-qualitÃ©",
        ),
        vertical_spacing=0.08,
    )

    # (1) Vue d'ensemble
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=ratings,
            mode="lines+markers",
            line=dict(color=ColorTheme.CHART_COLORS[3], width=2),
            marker=dict(size=4),
            name="Rating moyen mensuel",
            showlegend=True,
        ),
        row=1,
        col=1,
    )

    # Bandes de confiance
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"].tolist() + monthly_df["date"].tolist()[::-1],
            y=[upper_bound_weighted] * len(monthly_df)
            + [lower_bound_weighted] * len(monthly_df),
            fill="toself",
            fillcolor=ColorTheme.to_rgba(ColorTheme.ORANGE_SECONDARY, 0.2),
            line=dict(color="rgba(255,255,255,0)"),
            name=f"IC 95% (Â±{1.96 * std_rating_weighted / np.sqrt(np.sum(weights)):.3f})",
            showlegend=True,
        ),
        row=1,
        col=1,
    )

    # Tendance
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=trend_weighted_detailed,
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=2, dash="dash"),
            name=f"Tendance ({wls_trend_result.params[1]*12:.4f}/an)",
            showlegend=True,
        ),
        row=1,
        col=1,
    )

    # Moyenne
    fig.add_trace(
        go.Scatter(
            x=[monthly_df["date"].min(), monthly_df["date"].max()],
            y=[mean_rating_weighted, mean_rating_weighted],
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[0], width=2),
            name=f"Moyenne ({mean_rating_weighted:.3f})",
            showlegend=True,
        ),
        row=1,
        col=1,
    )

    # (2) Vue zoomÃ©e
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=ratings,
            mode="lines+markers",
            line=dict(color=ColorTheme.CHART_COLORS[3], width=2),
            marker=dict(size=6),
            name="Rating moyen mensuel",
            showlegend=False,
        ),
        row=2,
        col=1,
    )

    # Bandes de confiance zoomÃ©es
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"].tolist() + monthly_df["date"].tolist()[::-1],
            y=[upper_bound_weighted] * len(monthly_df)
            + [lower_bound_weighted] * len(monthly_df),
            fill="toself",
            fillcolor=ColorTheme.to_rgba(ColorTheme.ORANGE_SECONDARY, 0.3),
            line=dict(color="rgba(255,255,255,0)"),
            name=f"IC 95% (Â±{1.96 * std_rating_weighted / np.sqrt(np.sum(weights)):.4f})",
            showlegend=False,
        ),
        row=2,
        col=1,
    )

    # Tendance zoomÃ©e
    fig.add_trace(
        go.Scatter(
            x=monthly_df["date"],
            y=trend_weighted_detailed,
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=3, dash="dash"),
            name=f"Tendance ({wls_trend_result.params[1]*12:.4f}/an)",
            showlegend=False,
        ),
        row=2,
        col=1,
    )

    # Moyenne zoomÃ©e
    fig.add_trace(
        go.Scatter(
            x=[monthly_df["date"].min(), monthly_df["date"].max()],
            y=[mean_rating_weighted, mean_rating_weighted],
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[0], width=2),
            name=f"Moyenne ({mean_rating_weighted:.3f})",
            showlegend=False,
        ),
        row=2,
        col=1,
    )

    # (3) CorrÃ©lation volume-qualitÃ©
    sizes_detailed = weights_normalized * 800
    fig.add_trace(
        go.Scatter(
            x=volumes,
            y=ratings,
            mode="markers",
            marker=dict(
                size=sizes_detailed * 2,  # Points plus gros
                color=monthly_df["n_interactions"],
                colorscale="YlOrRd",  # Colorscale charte: Jaune â†’ Orange â†’ Rouge
                opacity=0.7,
                line=dict(width=0),  # Pas de contour
                colorbar=dict(title="Volume", x=1.0, len=0.25, y=0.12),
            ),
            showlegend=False,
        ),
        row=3,
        col=1,
    )

    # Ligne de rÃ©gression
    fig.add_trace(
        go.Scatter(
            x=volumes,
            y=vol_pred_detailed,
            mode="lines",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=3, dash="dash"),
            name=f"RÃ©gression pondÃ©rÃ©e (Ï={vol_qual_weighted:.3f})",
            showlegend=True,
        ),
        row=3,
        col=1,
    )

    # Axes
    fig.update_yaxes(title_text="Rating moyen", row=1, col=1)
    fig.update_yaxes(
        title_text="Rating moyen", row=2, col=1, range=[4.65, 4.72]
    )  # Zoom
    fig.update_xaxes(title_text="Nombre d'interactions mensuelles", row=3, col=1)
    fig.update_yaxes(title_text="Rating moyen", row=3, col=1)

    # Mise en forme
    fig.update_layout(
        height=1200,
        showlegend=True,
        title_text="Analyse dÃ©taillÃ©e avec bandes de confiance",
    )

    # Application du thÃ¨me
    chart_theme.apply_subplot_theme(fig, num_rows=3, num_cols=1)

    st.plotly_chart(fig, use_container_width=True)

    # MÃ©triques
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Moyenne pondÃ©rÃ©e", f"{mean_rating_weighted:.3f}")
    with col2:
        st.metric(
            "IC 95%", f"Â±{1.96 * std_rating_weighted / np.sqrt(np.sum(weights)):.4f}"
        )
    with col3:
        st.metric("Corr. volume-qualitÃ©", f"{vol_qual_weighted:.3f}")

    # InterprÃ©tation
    st.info(
        f"""
    ğŸ’¡ **InterprÃ©tation statistique**

    L'analyse dÃ©taillÃ©e confirme la **trÃ¨s forte stabilitÃ©** des ratings, avec une **moyenne pondÃ©rÃ©e** se situant Ã 
    **{mean_rating_weighted:.3f}**. Les **bandes de confiance Ã  95%** calculÃ©es sur la moyenne pondÃ©rÃ©e sont **extrÃªmement resserrÃ©es**
    (IC 95% = **Â±{1.96 * std_rating_weighted / np.sqrt(np.sum(weights)):.4f}**), ce qui dÃ©montre une **variance globale trÃ¨s faible** et une
    **grande prÃ©visibilitÃ©** du comportement de notation. Visuellement, bien que les notes mensuelles individuelles fluctuent lÃ©gÃ¨rement,
    elles restent **constamment groupÃ©es** autour de cette moyenne stable, renforÃ§ant la conclusion d'une **absence totale de tendance significative**
    Ã  long terme.
    """
    )


def analyse_ratings_seasonality_1() -> None:
    """Analyse 4: Statistiques descriptives des donnÃ©es saisonniÃ¨res."""
    st.markdown(
        """
        Analyse de la distribution des interactions et ratings par saison.
        Examine l'Ã©quilibre des donnÃ©es et la validitÃ© de l'analyse saisonniÃ¨re.
        """
    )

    # Chargement des donnÃ©es
    with st.spinner("Chargement des interactions..."):
        df_clean = load_clean_interactions()

    if df_clean.shape[0] == 0:
        st.error("âŒ Aucune donnÃ©e disponible")
        return

    df_pandas = df_clean.to_pandas()

    # Calcul des statistiques par saison
    seasonal_stats = (
        df_pandas.groupby("season")
        .agg(
            {
                "rating": ["mean", "std", "count"],
                "user_id": "nunique",
                "recipe_id": "nunique",
            }
        )
        .round(4)
    )

    seasonal_stats.columns = [
        "mean_rating",
        "std_rating",
        "count_ratings",
        "unique_users",
        "unique_recipes",
    ]
    seasonal_stats = seasonal_stats.reset_index()

    # Ordre logique des saisons
    season_order = ["Spring", "Summer", "Autumn", "Winter"]
    seasonal_stats["season_cat"] = pd.Categorical(
        seasonal_stats["season"], categories=season_order, ordered=True
    )
    seasonal_stats = seasonal_stats.sort_values("season_cat")

    # Informations sur les volumes
    volumes = seasonal_stats["count_ratings"].values
    cv_volumes = np.std(volumes) / np.mean(volumes)
    ratio_max_min = volumes.max() / volumes.min()
    volume_total = volumes.sum()

    # Graphique avec 2 subplots
    fig = make_subplots(
        rows=1,
        cols=2,
        subplot_titles=(
            "Distribution des interactions par saison",
            "Statistiques de rating par saison",
        ),
        specs=[[{"type": "bar"}, {"type": "bar"}]],
    )

    # (1) Volume d'interactions
    # Couleurs saisonniÃ¨res "Back to the Kitchen" (mÃªme palette que analyse_seasonality.py)
    season_colors_btk = {
        "Winter": ColorTheme.CHART_COLORS[1],  # Jaune dorÃ© (#FFD700)
        "Spring": ColorTheme.CHART_COLORS[2],  # Rouge/Orange profond (#E24E1B)
        "Summer": ColorTheme.ORANGE_PRIMARY,  # Orange vif (#FF8C00)
        "Autumn": ColorTheme.ORANGE_SECONDARY,  # Rouge/Orange profond (#E24E1B)
    }
    colors_season = [season_colors_btk[s] for s in seasonal_stats["season"]]
    fig.add_trace(
        go.Bar(
            x=seasonal_stats["season"],
            y=seasonal_stats["count_ratings"] / 1000,
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{int(v/1000)}K" for v in seasonal_stats["count_ratings"]],
            textposition="outside",
            textfont=dict(size=10, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=1,
        col=1,
    )

    # (2) Rating moyen
    fig.add_trace(
        go.Bar(
            x=seasonal_stats["season"],
            y=seasonal_stats["mean_rating"],
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{v:.4f}" for v in seasonal_stats["mean_rating"]],
            textposition="outside",
            textfont=dict(size=10, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=1,
        col=2,
    )

    # Axes
    fig.update_yaxes(title_text="Nombre (milliers)", row=1, col=1)
    fig.update_yaxes(title_text="Rating moyen", row=1, col=2)

    # Mise en forme
    fig.update_layout(
        height=500,
        showlegend=False,
        title_text=f"RÃ©partition saisonniÃ¨re (CV={cv_volumes:.3f}, Ratio={ratio_max_min:.2f}:1)",
    )

    # Application du thÃ¨me
    chart_theme.apply_subplot_theme(fig, num_rows=1, num_cols=2)

    st.plotly_chart(fig, use_container_width=True)

    # Affichage du tableau
    with st.expander("Voir les statistiques dÃ©taillÃ©es"):
        st.dataframe(
            seasonal_stats[
                [
                    "season",
                    "mean_rating",
                    "std_rating",
                    "count_ratings",
                    "unique_users",
                    "unique_recipes",
                ]
            ]
        )

    # MÃ©triques
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("CV Volumes", f"{cv_volumes:.3f}")
    with col2:
        st.metric("Ratio max/min", f"{ratio_max_min:.2f}:1")
    with col3:
        st.metric("Volume total", f"{volume_total:,}")
    with col4:
        st.metric("Saisons", f"{len(seasonal_stats)}")

    # InterprÃ©tation
    st.info(
        f"""
    ğŸ’¡ **InterprÃ©tation statistique**

    Les statistiques descriptives confirment la **validitÃ© de l'analyse saisonniÃ¨re**.
    Le volume d'interactions est **remarquablement bien Ã©quilibrÃ©** entre les quatre saisons, chacune reprÃ©sentant environ **25%** du total.
    Le **Coefficient de Variation ({cv_volumes:.3f})** et le **ratio max/min ({ratio_max_min:.2f}:1)** des volumes sont **extrÃªmement faibles**,
    indiquant qu'aucune saison ne pÃ¨se indÃ»ment sur l'analyse. Les comparaisons entre saisons seront donc **fiables et robustes**.
    """
    )


def analyse_ratings_seasonality_2() -> None:
    """Analyse 5: Variations saisonniÃ¨res des ratings (Stats et Visualisations)."""
    st.markdown(
        """
        Analyse dÃ©taillÃ©e des variations saisonniÃ¨res des ratings avec dashboard complet.
        Examine moyennes, pourcentages de ratings parfaits/nÃ©gatifs, et stabilitÃ© par saison.
        """
    )

    # Chargement des donnÃ©es
    with st.spinner("Chargement des interactions..."):
        df_clean = load_clean_interactions()

    if df_clean.shape[0] == 0:
        st.error("âŒ Aucune donnÃ©e disponible")
        return

    # --- PRÃ‰PARATION ET STATS ---
    seasonal_ratings = (
        df_clean.group_by("season")
        .agg(
            [
                pl.col("rating").mean().alias("mean_rating"),
                pl.col("rating").median().alias("median_rating"),
                pl.col("rating").std().alias("std_rating"),
                pl.len().alias("n_interactions"),
                pl.col("rating").quantile(0.25).alias("q25"),
                pl.col("rating").quantile(0.75).alias("q75"),
            ]
        )
        .to_pandas()
    )

    # Ordre logique des saisons
    season_order = ["Spring", "Summer", "Autumn", "Winter"]
    seasonal_ratings = (
        seasonal_ratings.set_index("season").loc[season_order].reset_index()
    )

    # Tests statistiques
    season_groups = [
        df_clean.filter(pl.col("season") == season)["rating"].to_pandas().tolist()
        for season in season_order
    ]
    f_stat, p_anova = f_oneway(*season_groups)
    h_stat, p_kruskal = kruskal(*season_groups)

    # Calcul % 5â˜… et % nÃ©gatifs
    seasonal_perfect = (
        df_clean.group_by("season")
        .agg([(pl.col("rating") == 5).sum().alias("count_5"), pl.len().alias("total")])
        .with_columns((pl.col("count_5") / pl.col("total") * 100).alias("pct_5_stars"))
        .to_pandas()
        .set_index("season")
        .loc[season_order]
        .reset_index()
    )

    seasonal_negative = (
        df_clean.group_by("season")
        .agg(
            [
                (pl.col("rating") <= 2).sum().alias("count_negative"),
                pl.len().alias("total"),
            ]
        )
        .with_columns(
            (pl.col("count_negative") / pl.col("total") * 100).alias("pct_negative")
        )
        .to_pandas()
        .set_index("season")
        .loc[season_order]
        .reset_index()
    )

    # --- VISUALISATION : Dashboard Saisonnier (6 panels) ---
    fig = make_subplots(
        rows=2,
        cols=3,
        subplot_titles=(
            "Variations saisonniÃ¨res (Radar)",
            "Rating moyen par saison",
            "% Ratings parfaits (5â˜…)",
            "% Ratings nÃ©gatifs (1-2â˜…)",
            "Ã‰cart-type des ratings",
            "Volume d'interactions",
        ),
        specs=[
            [{"type": "scatterpolar"}, {"type": "bar"}, {"type": "bar"}],
            [{"type": "bar"}, {"type": "bar"}, {"type": "bar"}],
        ],
        horizontal_spacing=0.12,
        vertical_spacing=0.15,
    )

    # Couleurs saisonniÃ¨res "Back to the Kitchen" (mÃªme palette que analyse_seasonality.py)
    season_colors_btk = {
        "Winter": ColorTheme.CHART_COLORS[1],  # Jaune dorÃ© (#FFD700)
        "Spring": ColorTheme.CHART_COLORS[2],  # Rouge/Orange profond (#E24E1B)
        "Summer": ColorTheme.ORANGE_PRIMARY,  # Orange vif (#FF8C00)
        "Autumn": ColorTheme.ORANGE_SECONDARY,  # Rouge/Orange profond (#E24E1B)
    }
    colors_season = [season_colors_btk[s] for s in seasonal_ratings["season"]]

    # 1. Radar chart
    theta = list(seasonal_ratings["season"]) + [seasonal_ratings["season"].iloc[0]]
    values = list(seasonal_ratings["mean_rating"]) + [
        seasonal_ratings["mean_rating"].iloc[0]
    ]

    fig.add_trace(
        go.Scatterpolar(
            r=values,
            theta=theta,
            mode="lines+markers",
            fill="toself",
            line=dict(color=ColorTheme.CHART_COLORS[2], width=3),
            marker=dict(size=8),
            fillcolor=ColorTheme.to_rgba(ColorTheme.ORANGE_SECONDARY, 0.25),
            showlegend=False,
        ),
        row=1,
        col=1,
    )

    fig.update_polars(radialaxis=dict(range=[4.5, 4.8]), row=1, col=1)

    # 2. Moyenne par saison
    fig.add_trace(
        go.Bar(
            x=seasonal_ratings["season"],
            y=seasonal_ratings["mean_rating"],
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{v:.4f}" for v in seasonal_ratings["mean_rating"]],
            textposition="outside",
            textfont=dict(size=9, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=1,
        col=2,
    )
    fig.update_yaxes(title_text="Rating moyen", range=[4.60, 4.70], row=1, col=2)

    # 3. % Ratings parfaits (5â˜…)
    fig.add_trace(
        go.Bar(
            x=seasonal_perfect["season"],
            y=seasonal_perfect["pct_5_stars"],
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{v:.2f}%" for v in seasonal_perfect["pct_5_stars"]],
            textposition="outside",
            textfont=dict(size=9, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=1,
        col=3,
    )
    fig.update_yaxes(title_text="% de ratings = 5", range=[74, 78], row=1, col=3)

    # 4. % Ratings nÃ©gatifs (1-2â˜…)
    fig.add_trace(
        go.Bar(
            x=seasonal_negative["season"],
            y=seasonal_negative["pct_negative"],
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{v:.2f}%" for v in seasonal_negative["pct_negative"]],
            textposition="outside",
            textfont=dict(size=9, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=2,
        col=1,
    )
    fig.update_yaxes(title_text="% de ratings â‰¤ 2", range=[0, 4], row=2, col=1)

    # 5. Ã‰cart-type
    fig.add_trace(
        go.Bar(
            x=seasonal_ratings["season"],
            y=seasonal_ratings["std_rating"],
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{v:.3f}" for v in seasonal_ratings["std_rating"]],
            textposition="outside",
            textfont=dict(size=9, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=2,
        col=2,
    )
    fig.update_yaxes(title_text="Ã‰cart-type", range=[0.0, 0.70], row=2, col=2)

    # 6. Volume d'interactions
    fig.add_trace(
        go.Bar(
            x=seasonal_ratings["season"],
            y=seasonal_ratings["n_interactions"] / 1000,
            marker=dict(color=colors_season, opacity=0.8, line=dict(width=0)),
            text=[f"{int(v/1000)}K" for v in seasonal_ratings["n_interactions"]],
            textposition="outside",
            textfont=dict(size=9, color=ColorTheme.TEXT_PRIMARY),
            showlegend=False,
        ),
        row=2,
        col=3,
    )
    fig.update_yaxes(title_text="Nombre (milliers)", row=2, col=3)

    # Mise en forme
    fig.update_layout(
        height=900,
        showlegend=False,
        title_text=f"Analyse des variations saisonniÃ¨res (ANOVA p={p_anova:.4f}, Kruskal p={p_kruskal:.4f})",
    )

    # Application du thÃ¨me
    chart_theme.apply_subplot_theme(fig, num_rows=2, num_cols=3)

    st.plotly_chart(fig, use_container_width=True)

    # MÃ©triques
    col1, col2, col3, col4 = st.columns(4)
    best_season = seasonal_ratings.loc[seasonal_ratings["mean_rating"].idxmax()]
    worst_season = seasonal_ratings.loc[seasonal_ratings["mean_rating"].idxmin()]

    with col1:
        st.metric("ANOVA F-stat", f"{f_stat:.3f}")
    with col2:
        st.metric("P-value", f"{p_anova:.4f}")
    with col3:
        st.metric(
            "Meilleure saison",
            f"{best_season['season']} ({best_season['mean_rating']:.4f})",
        )
    with col4:
        st.metric(
            "Ã‰cart max",
            f"{best_season['mean_rating'] - worst_season['mean_rating']:.4f}",
        )

    # InterprÃ©tation
    st.info(
        f"""
    ğŸ’¡ **InterprÃ©tation statistique**

    Les tests statistiques (ANOVA F={f_stat:.3f} et Kruskal-Wallis H={h_stat:.3f}) rÃ©vÃ¨lent des
    **diffÃ©rences statistiquement significatives** entre les saisons (p < 0.0001), **confirmant l'existence d'une variation saisonniÃ¨re**.
    Cependant, l'**ampleur de cette diffÃ©rence est infime** : l'Ã©cart entre la meilleure saison (**{best_season['season']}**, {best_season['mean_rating']:.3f})
    et la moins bonne (**{worst_season['season']}**, {worst_season['mean_rating']:.3f}) n'est que de **{best_season['mean_rating'] - worst_season['mean_rating']:.3f} points**
    sur une Ã©chelle de 5. L'analyse visuelle confirme la **stabilitÃ© globale**, mais rÃ©vÃ¨le un **schÃ©ma saisonnier cohÃ©rent**.
    MalgrÃ© une **significativitÃ© statistique irrÃ©futable**, l'**impact pratique de cette saisonnalitÃ© est nul**.
    """
    )


def render_ratings_analysis() -> None:
    """Point d'entrÃ©e principal pour les analyses de ratings."""
    st.markdown(
        '<h1 style="margin-top: 0; padding-top: 0;">â­ Analyses des Ratings (1999-2018)</h1>',
        unsafe_allow_html=True,
    )

    st.markdown(
        """
    Cette section prÃ©sente les analyses de **l'Ã©volution des ratings/notes** sur Food.com (1999-2018).

    Les analyses examinent la **stabilitÃ© temporelle**, les **tendances**, et les **variations saisonniÃ¨res**
    des notes moyennes attribuÃ©es aux recettes par les utilisateurs.
    """
    )

    # Affichage de toutes les analyses en continu (comme page SaisonnalitÃ©)

    st.subheader("ğŸ”¬ Validation mÃ©thodologique")
    analyse_ratings_validation_ponderee()
    st.markdown("---")

    st.subheader("ğŸ“ˆ Tendance temporelle")
    analyse_ratings_tendance_temporelle()
    st.markdown("---")

    st.subheader("ğŸ“Š Distribution et stabilitÃ©")
    analyse_ratings_distribution()
    st.markdown("---")

    st.subheader("ğŸ‚ Statistiques saisonniÃ¨res")
    analyse_ratings_seasonality_1()
    st.markdown("---")

    st.subheader("ğŸŒ¸ Variations saisonniÃ¨res")
    analyse_ratings_seasonality_2()
    st.markdown("---")
