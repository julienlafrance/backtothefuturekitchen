from .data_utils_common import *

# =============================================================================
# CHARGEMENT DES DONNÃ‰ES
# =============================================================================

def load_recipes_raw(db_path: Optional[Path] = None, limit: Optional[int] = None) -> pl.DataFrame:
    """Charge la table RAW_recipes complÃ¨te depuis DuckDB."""
    if db_path is None:
        db_path = get_db_path()

    sql = "SELECT * FROM RAW_recipes"
    if limit:
        sql += f" LIMIT {limit}"

    with duckdb.connect(database=str(db_path), read_only=True) as conn:
        df = conn.execute(sql).pl()

    print(f"âœ… RAW_recipes chargÃ©e ({df.shape[0]} lignes, {df.shape[1]} colonnes)")
    return df

# =============================================================================
# QUALITÃ‰ & NETTOYAGE
# =============================================================================

def analyze_recipe_quality(df: pl.DataFrame) -> Dict[str, any]:
    """Analyse de qualitÃ© spÃ©cifique aux recettes."""
    report = {
        "shape": df.shape,
        "columns": df.columns,
        "null_counts": df.null_count().to_dict(),
        "duplicate_count": df.is_duplicated().sum(),
    }

    # Statistiques basiques sur la durÃ©e
    if "minutes" in df.columns:
        report["minutes_stats"] = {
            "mean": df["minutes"].mean(),
            "median": df["minutes"].median(),
            "max": df["minutes"].max(),
            "min": df["minutes"].min()
        }

    # Sur le nombre d'ingrÃ©dients
    if "n_ingredients" in df.columns:
        report["ingredients_stats"] = {
            "mean": df["n_ingredients"].mean(),
            "median": df["n_ingredients"].median(),
            "max": df["n_ingredients"].max()
        }

    print(f"ğŸ“Š Rapport de qualitÃ© des recettes ({df.shape[0]} lignes)")
    print(f"Colonnes : {', '.join(df.columns)}")
    print(f"Doublons : {report['duplicate_count']}")
    print(f"Valeurs manquantes principales :")
    print({k: v for k, v in report['null_counts'].items() if v > 0})

    return report

# =============================================================================
# PARSING & ENRICHISSEMENT
# =============================================================================

def parse_nutrition_column(df: pl.DataFrame) -> pl.DataFrame:
    """DÃ©compose la colonne nutrition (liste de 7 Ã©lÃ©ments) en colonnes sÃ©parÃ©es."""
    if "nutrition" not in df.columns:
        return df

    return df.with_columns([
        pl.col("nutrition").str.strip_chars("[]").str.split(", ").alias("nutrition_list")
    ]).with_columns([
        pl.col("nutrition_list").list.get(0).cast(pl.Float64).alias("calories"),
        pl.col("nutrition_list").list.get(1).cast(pl.Float64).alias("total_fat_pct"),
        pl.col("nutrition_list").list.get(2).cast(pl.Float64).alias("sugar_pct"),
        pl.col("nutrition_list").list.get(3).cast(pl.Float64).alias("sodium_pct"),
        pl.col("nutrition_list").list.get(4).cast(pl.Float64).alias("protein_pct"),
        pl.col("nutrition_list").list.get(5).cast(pl.Float64).alias("sat_fat_pct"),
        pl.col("nutrition_list").list.get(6).cast(pl.Float64).alias("carb_pct")
    ]).drop("nutrition_list")

def add_recipe_time_features(df: pl.DataFrame) -> pl.DataFrame:
    """Ajoute des features temporelles Ã  partir de la date de soumission (rÃ©utilise add_calendar_features)."""
    if "submitted" not in df.columns:
        return df

    # VÃ©rifier si submitted est dÃ©jÃ  de type Date, sinon le parser
    submitted_dtype = df["submitted"].dtype
    
    if submitted_dtype == pl.Date:
        # DÃ©jÃ  une date, juste renommer
        df = df.with_columns([
            pl.col("submitted").alias("date")
        ])
    elif submitted_dtype == pl.Utf8 or submitted_dtype == pl.String:
        # C'est une string, parser en date
        df = df.with_columns([
            pl.col("submitted").str.strptime(pl.Date, "%Y-%m-%d", strict=False).alias("date")
        ])
    else:
        # Autre type, essayer de caster
        df = df.with_columns([
            pl.col("submitted").cast(pl.Date).alias("date")
        ])

    # RÃ©utiliser la fonction commune pour les features calendaires
    return add_calendar_features(df, date_col="date")

def compute_recipe_complexity(df: pl.DataFrame) -> pl.DataFrame:
    """CrÃ©e un score de complexitÃ© basÃ© sur minutes, n_steps, n_ingredients."""
    if not all(c in df.columns for c in ["minutes", "n_steps", "n_ingredients"]):
        return df

    return df.with_columns([
        ((pl.col("minutes").fill_null(0) / 10) +
         pl.col("n_steps").fill_null(0) +
         (pl.col("n_ingredients").fill_null(0) * 0.5)).alias("complexity_score")
    ])

def clean_and_enrich_recipes(df: pl.DataFrame) -> pl.DataFrame:
    """Pipeline complet pour nettoyer et enrichir les recettes."""
    # Nettoyage de base
    cleaned = df.drop_nulls(subset=["name", "submitted"])
    cleaned = cleaned.unique()
    
    # Filtrer les recettes avec minutes invalides (avant d'enrichir)
    if "minutes" in cleaned.columns:
        before = cleaned.height
        cleaned = cleaned.filter((pl.col("minutes") > 0) & (pl.col("minutes") <= 180))
        removed = before - cleaned.height
        if removed > 0:
            print(f"ğŸ§¹ Filtrage minutes : {removed:,} recettes retirÃ©es (<=0 ou >180 min)")

    # Enrichissement avec features
    enriched = (
        cleaned
        .pipe(parse_nutrition_column)
        .pipe(add_recipe_time_features)
        .pipe(compute_recipe_complexity)
    )
    print(f"âœ… Recettes nettoyÃ©es et enrichies : {enriched.shape}")
    return enriched

def load_clean_recipes(db_path: Optional[Path] = None) -> pl.DataFrame:
    """Charge les recettes nettoyÃ©es et enrichies prÃªtes Ã  lâ€™analyse."""
    df_raw = load_recipes_raw(db_path)
    return clean_and_enrich_recipes(df_raw)

# =============================================================================
# ANALYSES RAPIDES
# =============================================================================

def prepare_recipe_analysis(df: pl.DataFrame) -> Dict[str, pd.DataFrame]:
    """PrÃ©pare les datasets agrÃ©gÃ©s pour les analyses temporelles."""
    if "year" not in df.columns:
        df = add_recipe_time_features(df)

    return {
        "recipes_per_year": df.group_by("year").agg(pl.len().alias("n_recipes")).to_pandas(),
        "avg_duration_per_year": df.group_by("year").agg(pl.mean("minutes").alias("avg_minutes")).to_pandas(),
        "avg_complexity_per_season": df.group_by("season").agg(pl.mean("complexity_score").alias("mean_complexity")).to_pandas(),
        "avg_calories_per_year": df.group_by("year").agg(pl.mean("calories").alias("avg_calories")).to_pandas()
    }
