
from .data_utils_common import *

# =============================================================================
# LOADING
# =============================================================================

def load_interactions_raw(db_path: Optional[Path] = None) -> pl.DataFrame:
    """Charge la table RAW_interactions avec filtrage de base - EXCLUT les ratings √† 0."""
    if db_path is None:
        db_path = get_db_path()
    
    sql = """
    SELECT *
    FROM RAW_interactions
    WHERE rating BETWEEN 1 AND 5
      AND date IS NOT NULL
    """
    
    with duckdb.connect(database=str(db_path), read_only=True) as conn:
        return conn.execute(sql).pl()

def load_enriched_interactions(db_path: Optional[Path] = None) -> pl.DataFrame:
    """Charge interactions enrichies avec les donn√©es de recettes - EXCLUT les ratings √† 0."""
    if db_path is None:
        db_path = get_db_path()
    
    sql = """
    SELECT 
        i.user_id,
        i.recipe_id,
        i.date,
        i.rating,
        i.review,
        r.name as recipe_name,
        r.ingredients,
        r.tags,
        r.nutrition,
        r.n_steps,
        r.n_ingredients
    FROM RAW_interactions i
    LEFT JOIN RAW_recipes r ON i.recipe_id = r.id
    WHERE i.rating BETWEEN 1 AND 5
      AND i.date IS NOT NULL
    """
    
    with duckdb.connect(database=str(db_path), read_only=True) as conn:
        return conn.execute(sql).pl()
    
# =============================================================================
# TRANSFORMATIONS
# =============================================================================

def add_rating_features(df: pl.DataFrame, rating_col: str = "rating") -> pl.DataFrame:
    """Ajoute les features d√©riv√©es du rating (z-score normalis√©, cat√©gories)."""
    rating_mean = df[rating_col].mean()
    rating_std = df[rating_col].std()
    
    return df.with_columns([
        ((pl.col(rating_col) - rating_mean) / rating_std).alias("normalized_rating"),
        pl.when(pl.col(rating_col) <= 2).then(pl.lit("Low"))
          .when(pl.col(rating_col) <= 3).then(pl.lit("Medium"))
          .when(pl.col(rating_col) <= 4).then(pl.lit("High"))
          .otherwise(pl.lit("Excellent")).alias("rating_category"),
    ])

def clean_and_enrich_interactions(df: pl.DataFrame) -> pl.DataFrame:
    """Pipeline complet de nettoyage et enrichissement - EXCLUT les ratings √† 0 - retourne une copie transform√©e."""
    # Nettoyage de base (copie pour ne pas modifier l'original)
    # IMPORTANT: Exclut les ratings √† 0 car ils correspondent √† des interactions sans note
    cleaned = df.filter(
        (pl.col("rating").is_between(1, 5, closed="both")) &
        (pl.col("date").is_not_null())
    )
    
    # Suppression des duplicatas exacts
    cleaned = cleaned.unique()
    
    # Ajout des features
    enriched = add_calendar_features(cleaned)
    enriched = add_rating_features(enriched)
    
    return enriched

def load_clean_interactions(db_path: Optional[Path] = None) -> pl.DataFrame:
    """Charge et nettoie les interactions en une seule fois - version transform√©e pr√™te √† l'emploi."""
    raw_interactions = load_interactions_raw(db_path)
    return clean_and_enrich_interactions(raw_interactions)

# =============================================================================
# FONCTIONS INGR√âDIENTS - NOUVELLES
# =============================================================================

def extract_ingredients_from_string(ingredients_str: str) -> List[str]:
    """Extrait les ingr√©dients d'une string format "['ing1', 'ing2', ...]"."""
    if not ingredients_str or ingredients_str == 'null':
        return []
    
    # Supprime les crochets et guillemets, puis split sur les virgules
    cleaned = ingredients_str.strip("[]").replace("'", "").replace('"', '')
    ingredients = [ing.strip() for ing in cleaned.split(",")]
    
    # Filtre les √©l√©ments vides et normalise
    return [ing.lower().strip() for ing in ingredients if ing.strip()]

def explore_ingredients_format(db_path: Optional[Path] = None, n_samples: int = 10) -> Dict:
    """Fonction de test pour comprendre le format des ingr√©dients."""
    if db_path is None:
        db_path = get_db_path()
    
    # Charge quelques recettes avec ingr√©dients
    sql = """
    SELECT id as recipe_id, name, ingredients, n_ingredients
    FROM RAW_recipes 
    WHERE ingredients IS NOT NULL 
    LIMIT ?
    """
    
    with duckdb.connect(database=str(db_path), read_only=True) as conn:
        df_sample = conn.execute(sql, [n_samples]).pl()
    
    # Analyse du format
    analysis = {
        "sample_count": len(df_sample),
        "ingredients_samples": [],
        "format_analysis": {},
    }
    
    for row in df_sample.iter_rows(named=True):
        ingredients_str = row["ingredients"]
        extracted = extract_ingredients_from_string(ingredients_str)
        
        analysis["ingredients_samples"].append({
            "recipe_id": row["recipe_id"],
            "name": row["name"][:50] + "..." if len(row["name"]) > 50 else row["name"],
            "n_ingredients": row["n_ingredients"],
            "raw_string": ingredients_str[:100] + "..." if len(str(ingredients_str)) > 100 else ingredients_str,
            "extracted_count": len(extracted),
            "extracted_sample": extracted[:3]  # Premiers 3 ingr√©dients
        })
    
    # Stats globales
    all_extracted = []
    for sample in analysis["ingredients_samples"]:
        recipe_ingredients = extract_ingredients_from_string(
            df_sample.filter(pl.col("recipe_id") == sample["recipe_id"])["ingredients"][0]
        )
        all_extracted.extend(recipe_ingredients)
    
    analysis["format_analysis"] = {
        "total_ingredients_extracted": len(all_extracted),
        "unique_ingredients": len(set(all_extracted)),
        "most_common": pd.Series(all_extracted).value_counts().head(10).to_dict(),
        "avg_ingredients_per_recipe": len(all_extracted) / n_samples if n_samples > 0 else 0
    }
    
    return analysis

def load_ingredient_ratings(target_ingredients: List[str], db_path: Optional[Path] = None) -> pl.DataFrame:
    """
    Charge les ratings pour recettes contenant des ingr√©dients sp√©cifiques.
    
    SCH√âMA DU DATASET FINAL:
    - recipe_id: ID de la recette
    - user_id: ID utilisateur  
    - date: Date de l'interaction
    - rating: Note donn√©e (1-5)
    - ingredient_name: Nom de l'ingr√©dient trouv√©
    - recipe_name: Nom de la recette (pour debug)
    - n_ingredients: Nombre total ingr√©dients recette
    
    Une ligne par (recette √ó ingr√©dient_cible_trouv√© √ó interaction)
    """
    df_enriched = load_enriched_interactions(db_path)
    
    # Explode les ingr√©dients - chaque recette devient N lignes (1 par ingr√©dient)
    df_with_ingredients = (df_enriched
        .with_columns([
            # Extraction des ingr√©dients individuels  
            pl.col("ingredients").map_elements(
                lambda x: extract_ingredients_from_string(str(x)) if x else [],
                return_dtype=pl.List(pl.Utf8)
            ).alias("ingredient_list")
        ])
        .explode("ingredient_list")  # Explose la liste = 1 ligne par ingr√©dient
        .rename({"ingredient_list": "ingredient_name"})
        .filter(pl.col("ingredient_name") != "")  # Supprime les vides
    )
    
    # Filtre sur les ingr√©dients cibles seulement
    df_filtered = df_with_ingredients.filter(
        pl.col("ingredient_name").is_in([ing.lower().strip() for ing in target_ingredients])
    )
    
    # S√©lectionne les colonnes finales
    return df_filtered.select([
        "recipe_id", 
        "user_id", 
        "date", 
        "rating",
        "ingredient_name",
        "recipe_name",
        "n_ingredients"
    ])

# =============================================================================
# FONCTIONS D'ANALYSE SP√âCIALIS√âES
# =============================================================================

def prepare_volume_analysis(df: pl.DataFrame) -> Dict[str, pd.DataFrame]:
    """Pr√©pare les DataFrames pour l'analyse de volume (graphiques)."""
    return {
        "by_year": df.group_by("year").agg(pl.len().alias("n_interactions")).sort("year").to_pandas(),
        "by_month": df.group_by("month").agg(pl.len().alias("n_interactions")).sort("month").to_pandas(),
        "by_weekend": df.group_by("is_weekend").agg(pl.len().alias("n_interactions")).sort("is_weekend").to_pandas(),
        "by_season": df.group_by("season").agg(pl.len().alias("n_interactions")).to_pandas(),
    }

def prepare_rating_analysis(df: pl.DataFrame) -> Dict[str, pd.DataFrame]:
    """Pr√©pare les DataFrames pour l'analyse des ratings."""
    return {
        "monthly_stats": df.group_by("year", "month").agg([
            pl.col("rating").mean().alias("mean_rating"),
            pl.col("rating").median().alias("median_rating"),
            pl.col("rating").std().alias("std_rating"),
            pl.len().alias("n_interactions")
        ]).sort(["year", "month"]).to_pandas(),
        
        "seasonal_stats": df.group_by("season").agg([
            pl.col("rating").mean().alias("mean_rating"),
            pl.col("rating").median().alias("median_rating"),
            pl.col("rating").std().alias("std_rating"),
            pl.len().alias("n_interactions")
        ]).to_pandas(),
        
        "weekend_stats": df.group_by("is_weekend").agg([
            pl.col("rating").mean().alias("mean_rating"),
            pl.col("rating").median().alias("median_rating"),
            pl.col("rating").std().alias("std_rating"),
            pl.len().alias("n_interactions")
        ]).to_pandas(),
    }

# =============================================================================
# FONCTIONS DE TEST
# =============================================================================

def show_transformed_sample(df: pl.DataFrame, n: int = 5):
    """Affiche un √©chantillon format√© des donn√©es transform√©es."""
    print(f"üìä Aper√ßu des donn√©es transform√©es ({n} premi√®res lignes):")
    
    # Colonnes de base
    base_cols = ["user_id", "recipe_id", "date", "rating"]
    # Nouvelles colonnes ajout√©es
    new_cols = [col for col in df.columns if col not in base_cols]
    
    print(f"üÜï Nouvelles colonnes ajout√©es: {', '.join(new_cols)}")
    
    # Affichage avec s√©lection de colonnes importantes
    display_cols = base_cols + ["year", "month", "season", "is_weekend", "normalized_rating"]
    available_cols = [col for col in display_cols if col in df.columns]
    
    sample_df = df.select(available_cols).head(n)
    print(sample_df)
    
    return sample_df

def test_data_pipeline():
    """Test rapide du pipeline de donn√©es."""
    print("üß™ Test du pipeline de donn√©es...")
    
    # Test connexion
    db_path = get_db_path()
    print(f"‚úÖ DB trouv√©e: {db_path}")
    
    # Test chargement RAW (original, non modifi√©)
    df_raw = load_interactions_raw(db_path)
    print(f"‚úÖ RAW_interactions charg√©es: {df_raw.shape}")
    
    # Test qualit√© RAW
    report_raw = analyze_data_quality(df_raw, "RAW_interactions")
    print_quality_report(report_raw)
    
    # Test version transform√©e (copie enrichie)
    df_transformed = load_clean_interactions(db_path)
    print(f"\n‚úÖ Interactions transform√©es: {df_transformed.shape}")
    
    # Test qualit√© transform√©e
    report_transformed = analyze_data_quality(df_transformed, "TRANSFORMED_interactions")
    print_quality_report(report_transformed)
    
    # Aper√ßu format√© de la version transform√©e
    show_transformed_sample(df_transformed, n=5)
    
    return df_raw, df_transformed

# =============================================================================
# FONCTIONS POUR ANALYSES TEMPORELLES D'INGR√âDIENTS
# =============================================================================

def get_ingredients_for_analysis(analysis_type: str) -> List[str]:
    """
    Retourne la liste des ingr√©dients cibles selon le type d'analyse temporelle.
    
    Args:
        analysis_type: Type d'analyse ('long_term', 'seasonality', 'weekend')
    
    Returns:
        Liste des ingr√©dients s√©lectionn√©s pour l'analyse
    """
    # Ingr√©dients CORE (pr√©sents dans toutes les analyses)
    core_ingredients = ['salt', 'ground beef', 'eggs', 'onions', 'garlic']
    
    # Ingr√©dients sp√©cialis√©s par axe d'analyse
    if analysis_type == 'long_term':
        # Ingr√©dients avec >= 10 ans de donn√©es pour analyser les tendances long-terme
        specialized = ['butter', 'olive oil']
        return core_ingredients + specialized
    
    elif analysis_type == 'seasonality':
        # Ingr√©dients avec potentiel saisonnier fort
        specialized = ['butternut squash', 'asparagus', 'pumpkin']
        return core_ingredients + specialized
    
    elif analysis_type == 'weekend':
        # Tous les ingr√©dients disponibles (weekend a moins de contraintes)
        specialized = ['butternut squash', 'asparagus', 'pumpkin', 'butter', 'olive oil']
        return core_ingredients + specialized
    
    else:
        raise ValueError(f"Type d'analyse non support√©: {analysis_type}. "
                        f"Utilisez 'long_term', 'seasonality', ou 'weekend'.")

def load_ingredient_ratings(target_ingredients: List[str], db_path: Optional[Path] = None) -> pl.DataFrame:
    """
    Charge les donn√©es de ratings filtr√©es par ingr√©dients cibles.
    
    Args:
        target_ingredients: Liste des ingr√©dients √† analyser
        db_path: Chemin vers la base DuckDB (auto-d√©tect√© si None)
    
    Returns:
        DataFrame Polars avec les ratings des ingr√©dients s√©lectionn√©s
    """
    if db_path is None:
        db_path = get_db_path()
    
    # Cr√©ation de la clause WHERE pour les ingr√©dients
    ingredients_clause = "', '".join(target_ingredients)
    
    # Requ√™te optimis√©e avec jointure et filtrage
    query = f"""
    SELECT 
        i.date,
        i.rating,
        i.user_id,
        i.recipe_id,
        r.name as recipe_name,
        r.n_ingredients,
        ingredient.value as ingredient_name
    FROM RAW_interactions i
    JOIN RAW_recipes r ON i.recipe_id = r.id
    JOIN (
        SELECT 
            id as recipe_id,
            UNNEST(string_split(TRIM(ingredients, '[]'), ', ')) as ingredient_value
        FROM RAW_recipes
    ) ingredient_table ON r.id = ingredient_table.recipe_id
    JOIN (
        SELECT DISTINCT
            TRIM(value, ''' "''') as value
        FROM (
            SELECT UNNEST(string_split(TRIM(ingredients, '[]'), ', ')) as value
            FROM RAW_recipes
        )
        WHERE TRIM(value, ''' "''') IN ('{ingredients_clause}')
    ) ingredient ON TRIM(ingredient_table.ingredient_value, ''' "''') = ingredient.value
    WHERE 
        i.rating IS NOT NULL
        AND i.rating BETWEEN 1 AND 5  -- üõ†Ô∏è CORRECTION: Exclut les ratings √† 0
        AND i.date IS NOT NULL
        AND r.ingredients IS NOT NULL
        AND LENGTH(r.ingredients) > 2
    ORDER BY i.date, ingredient.value
    """
    
    with duckdb.connect(database=str(db_path), read_only=True) as conn:
        df = conn.execute(query).pl()
    
    print(f"‚úÖ Donn√©es charg√©es: {df.shape[0]:,} interactions pour {len(target_ingredients)} ingr√©dients")
    
    return df

# =============================================================================
# POINT D'ENTR√âE PRINCIPAL
# =============================================================================

if __name__ == "__main__":
    # Ex√©cution du test si ce module est lanc√© directement
    test_data_pipeline()