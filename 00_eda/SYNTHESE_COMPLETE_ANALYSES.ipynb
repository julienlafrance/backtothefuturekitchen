{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85492ba",
   "metadata": {},
   "source": [
    "# ğŸ“Š SYNTHÃˆSE COMPLÃˆTE DES ANALYSES TEMPORELLES\n",
    "\n",
    "\n",
    "**Date**: 17 octobre 2025  \n",
    "**Dataset**: MangeTaMain - Analyses Rating Temporelles  \n",
    "**Status**: âœ… DonnÃ©es nettoyÃ©es (ratings=0 supprimÃ©s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7fc9bd",
   "metadata": {},
   "source": [
    "# ğŸ¯ SYNTHÃˆSE COMPLÃˆTE DES ANALYSES TEMPORELLES\n",
    "\n",
    "**ExÃ©cution complÃ¨te des 3 analyses prioritaires avec rÃ©sultats business**\n",
    "\n",
    "## ğŸ“‹ Analyses implÃ©mentÃ©es:\n",
    "1. **ğŸ¯ Weekend Analysis** - Patterns weekend vs semaine\n",
    "2. **ğŸŒ¸ Seasonality Analysis** - Cycles saisonniers et mensuels  \n",
    "3. **ğŸ“ˆ Long Term Analysis** - Tendances et Ã©volutions temporelles\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š SYNTHÃˆSE COMPLÃˆTE - ANALYSES MANGETAMAIN\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ SYNTHÃˆSE COMPLÃˆTE DES ANALYSES - MANGETAMAIN KITCHEN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Imports complets\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\".\").resolve()))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, mannwhitneyu, linregress\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration visuelle\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Imports rÃ©ussis\")\n",
    "\n",
    "# Chargement des utilities\n",
    "exec(open(\"00_data_utils.ipynb\").read())\n",
    "\n",
    "# Test des donnÃ©es\n",
    "df_clean = load_clean_interactions()\n",
    "print(f\"âœ… DonnÃ©es chargÃ©es: {df_clean.shape}\")\n",
    "print(f\"ğŸ“Š Colonnes disponibles: {list(df_clean.columns)}\")\n",
    "\n",
    "# VÃ©rification qualitÃ©\n",
    "quality_report = check_data_quality(df_clean)\n",
    "print(\"\\nğŸ” RAPPORT QUALITÃ‰:\")\n",
    "for metric, value in quality_report.items():\n",
    "    print(f\"  â€¢ {metric}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ PrÃªt pour les 3 analyses:\")\n",
    "print(f\"  1. ğŸ“… Weekend Effect Analysis\")\n",
    "print(f\"  2. ğŸŒ Seasonality Analysis\")\n",
    "print(f\"  3. ğŸ“ˆ Long Term Trends Analysis\")\n",
    "\n",
    "# PrÃ©paration des datasets globaux\n",
    "monthly_stats = df_clean.group_by([\"year\", \"month\"]).agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.col(\"rating\").median().alias(\"median_rating\"),\n",
    "    pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "]).sort([\"year\", \"month\"])\n",
    "\n",
    "daily_stats = df_clean.group_by([\"year\", \"month\", \"day\"]).agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "]).sort([\"year\", \"month\", \"day\"])\n",
    "\n",
    "weekend_stats = df_clean.group_by([\"is_weekend\"]).agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.col(\"rating\").median().alias(\"median_rating\"),\n",
    "    pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "])\n",
    "\n",
    "seasonal_stats = df_clean.group_by([\"season\"]).agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.col(\"rating\").median().alias(\"median_rating\"),\n",
    "    pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "])\n",
    "\n",
    "print(f\"\\n\udcc8 Datasets prÃ©parÃ©s:\")\n",
    "print(f\"  â€¢ Monthly: {monthly_stats.shape}\")\n",
    "print(f\"  â€¢ Daily: {daily_stats.shape}\")\n",
    "print(f\"  â€¢ Weekend: {weekend_stats.shape}\")\n",
    "print(f\"  â€¢ Seasonal: {seasonal_stats.shape}\")\n",
    "\n",
    "print(\"\\nâœ… INITIALISATION TERMINÃ‰E - PrÃªt pour les analyses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869afdb",
   "metadata": {},
   "source": [
    "## ğŸ¯ 1. WEEKEND ANALYSIS - RÃ©sultats Complets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f285e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ WEEKEND ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 1.1 Weekend vs Weekday Test\n",
    "weekend_comparison = df_clean.group_by(\"is_weekend\").agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "]).sort(\"is_weekend\").to_pandas()\n",
    "\n",
    "weekend_ratings = df_clean.filter(pl.col(\"is_weekend\") == 1)[\"rating\"].to_numpy()\n",
    "weekday_ratings = df_clean.filter(pl.col(\"is_weekend\") == 0)[\"rating\"].to_numpy()\n",
    "\n",
    "# Test statistique\n",
    "statistic, p_value = mannwhitneyu(weekend_ratings, weekday_ratings, alternative='two-sided')\n",
    "pooled_std = np.sqrt((np.std(weekend_ratings, ddof=1)**2 + np.std(weekday_ratings, ddof=1)**2) / 2)\n",
    "cohens_d = (np.mean(weekend_ratings) - np.mean(weekday_ratings)) / pooled_std\n",
    "\n",
    "print(f\"\\nğŸ“Š Weekend vs Semaine:\")\n",
    "print(f\"â€¢ Weekend: {np.mean(weekend_ratings):.4f} Â± {np.std(weekend_ratings):.4f}\")\n",
    "print(f\"â€¢ Semaine: {np.mean(weekday_ratings):.4f} Â± {np.std(weekday_ratings):.4f}\")\n",
    "print(f\"â€¢ DiffÃ©rence: {np.mean(weekend_ratings) - np.mean(weekday_ratings):+.4f} points\")\n",
    "print(f\"â€¢ P-valeur: {p_value:.4f} ({'SIGNIFICATIF' if p_value < 0.05 else 'NON SIGNIFICATIF'})\")\n",
    "print(f\"â€¢ Cohen's d: {cohens_d:.4f} ({'Petit' if abs(cohens_d) < 0.2 else 'Moyen' if abs(cohens_d) < 0.5 else 'Grand'} effet)\")\n",
    "\n",
    "# 1.2 Patterns par jour\n",
    "day_names = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "weekday_patterns = df_clean.group_by(\"weekday\").agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "]).sort(\"weekday\").to_pandas()\n",
    "weekday_patterns[\"day_name\"] = day_names\n",
    "\n",
    "best_day = weekday_patterns.loc[weekday_patterns[\"mean_rating\"].idxmax()]\n",
    "worst_day = weekday_patterns.loc[weekday_patterns[\"mean_rating\"].idxmin()]\n",
    "\n",
    "print(f\"\\nğŸ“… Patterns journaliers:\")\n",
    "print(f\"â€¢ Meilleur jour: {best_day['day_name']} ({best_day['mean_rating']:.4f})\")\n",
    "print(f\"â€¢ Pire jour: {worst_day['day_name']} ({worst_day['mean_rating']:.4f})\")\n",
    "print(f\"â€¢ Amplitude: {weekday_patterns['mean_rating'].max() - weekday_patterns['mean_rating'].min():.4f} points\")\n",
    "\n",
    "# Visualisation Weekend\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\"Weekend vs Semaine\", \"Patterns par jour\"],\n",
    "    specs=[[{\"type\": \"xy\"}, {\"type\": \"xy\"}]]\n",
    ")\n",
    "\n",
    "# Violin plot weekend\n",
    "fig.add_trace(go.Violin(\n",
    "    y=weekday_ratings,\n",
    "    name=\"Semaine\",\n",
    "    box_visible=True,\n",
    "    fillcolor=\"lightblue\"\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Violin(\n",
    "    y=weekend_ratings,\n",
    "    name=\"Weekend\",\n",
    "    box_visible=True,\n",
    "    fillcolor=\"lightcoral\"\n",
    "), row=1, col=1)\n",
    "\n",
    "# Bar chart journalier\n",
    "fig.add_trace(go.Bar(\n",
    "    x=weekday_patterns[\"day_name\"],\n",
    "    y=weekday_patterns[\"mean_rating\"],\n",
    "    text=[f\"{val:.3f}\" for val in weekday_patterns[\"mean_rating\"]],\n",
    "    textposition=\"outside\",\n",
    "    marker_color=[\"red\" if i in [0,1] else \"orange\" if i in [2,3] else \"green\" for i in range(7)]\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Weekend Analysis (Cohen's d = {cohens_d:.3f}, p = {p_value:.4f})\",\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "weekend_result = {\n",
    "    \"effet_weekend\": np.mean(weekend_ratings) - np.mean(weekday_ratings),\n",
    "    \"significatif\": p_value < 0.05,\n",
    "    \"meilleur_jour\": best_day['day_name'],\n",
    "    \"pire_jour\": worst_day['day_name']\n",
    "}\n",
    "\n",
    "print(f\"âœ… Weekend Analysis terminÃ©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6753f9",
   "metadata": {},
   "source": [
    "## ğŸŒ¸ 2. SEASONALITY ANALYSIS - RÃ©sultats Complets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99150c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸŒ¸ SEASONALITY ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 2.1 Analyse saisonniÃ¨re\n",
    "season_order = [\"Spring\", \"Summer\", \"Autumn\", \"Winter\"]\n",
    "seasonal_ratings = df_clean.group_by(\"season\").agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "]).to_pandas()\n",
    "\n",
    "seasonal_ratings = seasonal_ratings.set_index('season').loc[season_order].reset_index()\n",
    "\n",
    "# Test ANOVA\n",
    "season_groups = [df_clean.filter(pl.col(\"season\") == season)[\"rating\"].to_list() \n",
    "                for season in season_order]\n",
    "f_stat, p_anova = f_oneway(*season_groups)\n",
    "\n",
    "best_season = seasonal_ratings.loc[seasonal_ratings['mean_rating'].idxmax(), 'season']\n",
    "worst_season = seasonal_ratings.loc[seasonal_ratings['mean_rating'].idxmin(), 'season']\n",
    "seasonal_range = seasonal_ratings['mean_rating'].max() - seasonal_ratings['mean_rating'].min()\n",
    "\n",
    "print(f\"\\nğŸŒ¸ Variations saisonniÃ¨res:\")\n",
    "display(seasonal_ratings[['season', 'mean_rating', 'std_rating', 'n_interactions']])\n",
    "print(f\"â€¢ ANOVA p-valeur: {p_anova:.4f} ({'SIGNIFICATIF' if p_anova < 0.05 else 'NON SIGNIFICATIF'})\")\n",
    "print(f\"â€¢ Meilleure saison: {best_season} ({seasonal_ratings.loc[seasonal_ratings['season']==best_season, 'mean_rating'].iloc[0]:.4f})\")\n",
    "print(f\"â€¢ Pire saison: {worst_season} ({seasonal_ratings.loc[seasonal_ratings['season']==worst_season, 'mean_rating'].iloc[0]:.4f})\")\n",
    "print(f\"â€¢ Ã‰cart saisonnier: {seasonal_range:.4f} points\")\n",
    "\n",
    "# 2.2 Patterns mensuels\n",
    "monthly_patterns = df_clean.group_by(\"month\").agg([\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\"),\n",
    "    pl.len().alias(\"n_interactions\")\n",
    "]).sort(\"month\").to_pandas()\n",
    "\n",
    "month_names = [\"Jan\", \"FÃ©v\", \"Mar\", \"Avr\", \"Mai\", \"Jun\", \"Jul\", \"AoÃ»\", \"Sep\", \"Oct\", \"Nov\", \"DÃ©c\"]\n",
    "monthly_patterns[\"month_name\"] = month_names\n",
    "\n",
    "best_month = monthly_patterns.loc[monthly_patterns['mean_rating'].idxmax()]\n",
    "worst_month = monthly_patterns.loc[monthly_patterns['mean_rating'].idxmin()]\n",
    "\n",
    "print(f\"\\nğŸ“… Patterns mensuels:\")\n",
    "print(f\"â€¢ Meilleur mois: {best_month['month_name']} ({best_month['mean_rating']:.4f})\")\n",
    "print(f\"â€¢ Pire mois: {worst_month['month_name']} ({worst_month['mean_rating']:.4f})\")\n",
    "\n",
    "# Visualisation Seasonality\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\"Ratings par saison\", \"Pattern polaire mensuel\", \"Heatmap annÃ©eÃ—mois\", \"CyclicitÃ© FFT\"],\n",
    "    specs=[[{\"type\": \"xy\"}, {\"type\": \"polar\"}], \n",
    "           [{\"type\": \"xy\"}, {\"type\": \"xy\"}]]\n",
    ")\n",
    "\n",
    "# 1. Box plots saisons\n",
    "season_colors = {\"Spring\": \"lightgreen\", \"Summer\": \"gold\", \"Autumn\": \"orange\", \"Winter\": \"lightblue\"}\n",
    "for season in season_order:\n",
    "    season_data = df_clean.filter(pl.col(\"season\") == season)[\"rating\"].to_list()\n",
    "    fig.add_trace(go.Box(\n",
    "        y=season_data,\n",
    "        name=season,\n",
    "        marker_color=season_colors[season]\n",
    "    ), row=1, col=1)\n",
    "\n",
    "# 2. Radar mensuel\n",
    "fig.add_trace(go.Scatterpolar(\n",
    "    r=monthly_patterns[\"mean_rating\"],\n",
    "    theta=monthly_patterns[\"month_name\"],\n",
    "    fill='toself',\n",
    "    name='Rating mensuel'\n",
    "), row=1, col=2)\n",
    "\n",
    "# 3. Heatmap (simplifiÃ©)\n",
    "year_month_grid = df_clean.group_by([\"year\", \"month\"]).agg(\n",
    "    pl.col(\"rating\").mean().alias(\"mean_rating\")\n",
    ").to_pandas()\n",
    "heatmap_data = year_month_grid.pivot(index='year', columns='month', values='mean_rating')\n",
    "\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=heatmap_data.values,\n",
    "    x=[month_names[i-1] for i in heatmap_data.columns],\n",
    "    y=heatmap_data.index,\n",
    "    colorscale=\"RdYlBu_r\"\n",
    "), row=2, col=1)\n",
    "\n",
    "# 4. FFT analysis\n",
    "monthly_series = monthly_patterns[\"mean_rating\"].values\n",
    "fft_values = np.abs(fft(monthly_series))\n",
    "frequencies = fftfreq(len(monthly_series))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=frequencies[:len(frequencies)//2],\n",
    "    y=fft_values[:len(fft_values)//2],\n",
    "    mode='lines+markers',\n",
    "    name='Spectrum'\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Seasonality Analysis (ANOVA p = {p_anova:.4f})\",\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "seasonality_result = {\n",
    "    \"ecart_saisonnier\": seasonal_range,\n",
    "    \"significatif\": p_anova < 0.05,\n",
    "    \"meilleure_saison\": best_season,\n",
    "    \"pire_saison\": worst_season,\n",
    "    \"meilleur_mois\": best_month['month_name'],\n",
    "    \"pire_mois\": worst_month['month_name']\n",
    "}\n",
    "\n",
    "print(f\"âœ… Seasonality Analysis terminÃ©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbca5d",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 3. LONG TERM ANALYSIS - RÃ©sultats Complets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \udd0d ANALYSE 3: LONG TERM TRENDS\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“ˆ ANALYSE 3: TENDANCES LONG TERME\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def mann_kendall_test(data):\n",
    "    \"\"\"Test de Mann-Kendall pour dÃ©tecter les tendances monotones\"\"\"\n",
    "    n = len(data)\n",
    "    s = 0\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            if data[j] > data[i]:\n",
    "                s += 1\n",
    "            elif data[j] < data[i]:\n",
    "                s -= 1\n",
    "    \n",
    "    var_s = n * (n-1) * (2*n+5) / 18\n",
    "    \n",
    "    if s > 0:\n",
    "        z = (s - 1) / np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1) / np.sqrt(var_s)\n",
    "    else:\n",
    "        z = 0\n",
    "    \n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    return z, p_value, s\n",
    "\n",
    "# 1. Test de tendance sur les ratings mensuels\n",
    "monthly_analysis = monthly_stats.to_pandas()\n",
    "monthly_ratings = monthly_analysis['mean_rating'].values\n",
    "\n",
    "z_mk, p_mk, s_mk = mann_kendall_test(monthly_ratings)\n",
    "\n",
    "print(f\"ğŸ” Test de Mann-Kendall - Tendance Long Terme:\")\n",
    "print(f\"Statistique S: {s_mk}\")\n",
    "print(f\"Z-score: {z_mk:.4f}\")\n",
    "print(f\"P-value: {p_mk:.4f}\")\n",
    "\n",
    "if p_mk < 0.05:\n",
    "    direction = \"HAUSSE\" if s_mk > 0 else \"BAISSE\"\n",
    "    print(f\"âœ… TENDANCE SIGNIFICATIVE: {direction}\")\n",
    "else:\n",
    "    print(f\"âŒ Pas de tendance claire dÃ©tectÃ©e\")\n",
    "\n",
    "# 2. RÃ©gression pour quantifier l'Ã©volution\n",
    "X = np.arange(len(monthly_analysis))\n",
    "y = monthly_analysis['mean_rating'].values\n",
    "slope, intercept, r_value, p_value, std_err = linregress(X, y)\n",
    "\n",
    "print(f\"\\n\udcca RÃ©gression linÃ©aire:\")\n",
    "print(f\"Pente: {slope:.6f} points/mois\")\n",
    "print(f\"RÂ²: {r_value**2:.4f}\")\n",
    "print(f\"Evolution annuelle: {slope * 12:.4f} points/an\")\n",
    "\n",
    "# 3. DÃ©tection des points de rupture (changements structurels)\n",
    "def detect_breakpoints(data, window=6):\n",
    "    \"\"\"DÃ©tection simple de points de rupture par variance glissante\"\"\"\n",
    "    rolling_mean = pd.Series(data).rolling(window).mean()\n",
    "    rolling_std = pd.Series(data).rolling(window).std()\n",
    "    \n",
    "    # Normalisation pour dÃ©tecter les anomalies\n",
    "    normalized = (pd.Series(data) - rolling_mean) / rolling_std\n",
    "    breakpoints = np.where(np.abs(normalized) > 2)[0]  # > 2 sigma\n",
    "    \n",
    "    return breakpoints\n",
    "\n",
    "breakpoints = detect_breakpoints(monthly_ratings)\n",
    "print(f\"\\nğŸ” Points de rupture dÃ©tectÃ©s: {len(breakpoints)}\")\n",
    "if len(breakpoints) > 0:\n",
    "    print(f\"Mois concernÃ©s: {breakpoints}\")\n",
    "\n",
    "# 4. Evolution des power users\n",
    "power_users_evolution = df_clean.filter(\n",
    "    pl.col(\"user_id\").is_in(\n",
    "        df_clean.group_by(\"user_id\").len().filter(\n",
    "            pl.col(\"len\") >= pl.col(\"len\").quantile(0.8)\n",
    "        ).select(\"user_id\").to_series()\n",
    "    )\n",
    ").group_by([\"year\", \"month\"]).agg([\n",
    "    pl.col(\"rating\").mean().alias(\"power_user_avg_rating\"),\n",
    "    pl.len().alias(\"power_user_interactions\")\n",
    "]).sort([\"year\", \"month\"]).to_pandas()\n",
    "\n",
    "# CorrÃ©lation entre activitÃ© gÃ©nÃ©rale et power users\n",
    "if len(power_users_evolution) > 5:\n",
    "    corr_power, p_power = spearmanr(\n",
    "        monthly_analysis['mean_rating'].values[:len(power_users_evolution)],\n",
    "        power_users_evolution['power_user_avg_rating'].values\n",
    "    )\n",
    "    print(f\"\\nğŸ‘¥ Power Users - CorrÃ©lation avec tendance gÃ©nÃ©rale:\")\n",
    "    print(f\"Ï = {corr_power:.3f} (p = {p_power:.4f})\")\n",
    "\n",
    "# 5. Visualisation complÃ¨te\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        \"Evolution Ratings Temporelle\",\n",
    "        \"Volume vs QualitÃ©\",\n",
    "        \"Power Users vs GÃ©nÃ©ral\",\n",
    "        \"Distribution par PÃ©riode\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Graphique 1: Evolution temporelle avec tendance\n",
    "dates = pd.to_datetime(monthly_analysis[['year', 'month']].assign(day=1))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dates,\n",
    "    y=monthly_analysis['mean_rating'],\n",
    "    mode='lines+markers',\n",
    "    name='Rating moyen',\n",
    "    line=dict(color='blue', width=2)\n",
    "), row=1, col=1)\n",
    "\n",
    "# Ligne de tendance\n",
    "trend_line = intercept + slope * X\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dates,\n",
    "    y=trend_line,\n",
    "    mode='lines',\n",
    "    name=f'Tendance ({slope:.4f}/mois)',\n",
    "    line=dict(color='red', dash='dash', width=2)\n",
    "), row=1, col=1)\n",
    "\n",
    "# Marquage des breakpoints\n",
    "if len(breakpoints) > 0:\n",
    "    for bp in breakpoints:\n",
    "        if bp < len(dates):\n",
    "            fig.add_vline(\n",
    "                x=dates.iloc[bp],\n",
    "                line_dash=\"dot\",\n",
    "                line_color=\"orange\",\n",
    "                row=1, col=1\n",
    "            )\n",
    "\n",
    "# Graphique 2: Volume vs QualitÃ©\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=monthly_analysis['n_interactions'],\n",
    "    y=monthly_analysis['mean_rating'],\n",
    "    mode='markers',\n",
    "    name='Volume-QualitÃ©',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=monthly_analysis.index,\n",
    "        colorscale='Viridis',\n",
    "        showscale=True\n",
    "    )\n",
    "), row=1, col=2)\n",
    "\n",
    "# Graphique 3: Power users comparison (si donnÃ©es disponibles)\n",
    "if len(power_users_evolution) > 0:\n",
    "    dates_power = pd.to_datetime(power_users_evolution[['year', 'month']].assign(day=1))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates_power,\n",
    "        y=power_users_evolution['power_user_avg_rating'],\n",
    "        mode='lines',\n",
    "        name='Power Users',\n",
    "        line=dict(color='green')\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates[:len(power_users_evolution)],\n",
    "        y=monthly_analysis['mean_rating'].values[:len(power_users_evolution)],\n",
    "        mode='lines',\n",
    "        name='Utilisateurs gÃ©nÃ©raux',\n",
    "        line=dict(color='blue')\n",
    "    ), row=2, col=1)\n",
    "\n",
    "# Graphique 4: Distribution par pÃ©riode\n",
    "periods = ['DÃ©but', 'Milieu', 'RÃ©cent']\n",
    "n_total = len(monthly_ratings)\n",
    "period_size = n_total // 3\n",
    "\n",
    "period_means = [\n",
    "    np.mean(monthly_ratings[:period_size]),\n",
    "    np.mean(monthly_ratings[period_size:2*period_size]),\n",
    "    np.mean(monthly_ratings[2*period_size:])\n",
    "]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=periods,\n",
    "    y=period_means,\n",
    "    name='Rating par pÃ©riode',\n",
    "    marker_color=['lightblue', 'lightgreen', 'lightcoral']\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Long Term Analysis - Tendance: {slope:+.4f}/mois (p={p_mk:.4f})\",\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 6. SynthÃ¨se Business\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"ğŸ’¼ SYNTHÃˆSE BUSINESS - LONG TERME\")\n",
    "print(f\"=\"*50)\n",
    "\n",
    "if p_mk < 0.05:\n",
    "    trend_desc = \"amÃ©lioration\" if slope > 0 else \"dÃ©gradation\"\n",
    "    annual_change = slope * 12\n",
    "    print(f\"ğŸ“ˆ TENDANCE CONFIRMÃ‰E: {trend_desc} de {abs(annual_change):.3f} points/an\")\n",
    "    print(f\"ğŸ¯ En {int(1/abs(slope))} mois: changement d'1 point de rating\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š STABILITÃ‰: Pas d'Ã©volution significative dÃ©tectÃ©e\")\n",
    "\n",
    "print(f\"ğŸ” FiabilitÃ© du modÃ¨le: RÂ² = {r_value**2:.3f}\")\n",
    "\n",
    "if len(breakpoints) > 0:\n",
    "    print(f\"âš ï¸  RUPTURES DÃ‰TECTÃ‰ES: {len(breakpoints)} changements structurels\")\n",
    "else:\n",
    "    print(f\"âœ… Ã‰VOLUTION RÃ‰GULIÃˆRE: Pas de rupture majeure\")\n",
    "\n",
    "# Recommandations\n",
    "print(f\"\\nğŸ“‹ RECOMMANDATIONS:\")\n",
    "if slope > 0 and p_mk < 0.05:\n",
    "    print(f\"  â€¢ âœ… Maintenir la stratÃ©gie actuelle (amÃ©lioration continue)\")\n",
    "    print(f\"  â€¢ ğŸ¯ Identifier les facteurs de cette amÃ©lioration\")\n",
    "elif slope < 0 and p_mk < 0.05:\n",
    "    print(f\"  â€¢ âš ï¸  Investiguer les causes de dÃ©gradation\")\n",
    "    print(f\"  â€¢ ğŸ”§ Plan d'action correctif nÃ©cessaire\")\n",
    "else:\n",
    "    print(f\"  â€¢ ğŸ“Š Surveillance continue requise\")\n",
    "    print(f\"  â€¢ ğŸ’¡ OpportunitÃ© d'innovation pour crÃ©er une tendance positive\")\n",
    "\n",
    "print(f\"\\nâœ… ANALYSE LONG TERME TERMINÃ‰E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052458d0",
   "metadata": {},
   "source": [
    "## ğŸ¯ 4. SYNTHÃˆSE FINALE & IMPLICATIONS BUSINESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaebb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ SYNTHÃˆSE FINALE DES 3 ANALYSES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compilation des rÃ©sultats\n",
    "results_summary = {\n",
    "    \"ğŸ¯ WEEKEND ANALYSIS\": {\n",
    "        \"Effet weekend\": f\"{weekend_result['effet_weekend']:+.4f} points\",\n",
    "        \"Significatif\": \"OUI\" if weekend_result['significatif'] else \"NON\",\n",
    "        \"Meilleur jour\": weekend_result['meilleur_jour'],\n",
    "        \"Pire jour\": weekend_result['pire_jour'],\n",
    "        \"Implication\": \"Weekend plus gÃ©nÃ©reux\" if weekend_result['effet_weekend'] > 0 else \"Weekend plus sÃ©vÃ¨re\"\n",
    "    },\n",
    "    \n",
    "    \"ğŸŒ¸ SEASONALITY ANALYSIS\": {\n",
    "        \"Ã‰cart saisonnier\": f\"{seasonality_result['ecart_saisonnier']:.4f} points\",\n",
    "        \"Significatif\": \"OUI\" if seasonality_result['significatif'] else \"NON\",\n",
    "        \"Meilleure saison\": seasonality_result['meilleure_saison'],\n",
    "        \"Pire saison\": seasonality_result['pire_saison'],\n",
    "        \"Meilleur mois\": seasonality_result['meilleur_mois'],\n",
    "        \"Pire mois\": seasonality_result['pire_mois']\n",
    "    },\n",
    "    \n",
    "    \"ğŸ“ˆ LONG TERM ANALYSIS\": {\n",
    "        \"Tendance mensuelle\": f\"{longterm_result['tendance']:+.6f} points/mois\",\n",
    "        \"Significatif\": \"OUI\" if longterm_result['significatif'] else \"NON\",\n",
    "        \"Ã‰volution annuelle\": f\"{longterm_result['evolution_annuelle']:+.4f} points/an\",\n",
    "        \"Volume-QualitÃ©\": f\"{longterm_result['correlation_volume_qualite']:+.4f}\",\n",
    "        \"Direction\": \"AmÃ©lioration\" if longterm_result['tendance'] > 0 else \"DÃ©gradation\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for analysis, metrics in results_summary.items():\n",
    "    print(f\"\\n{analysis}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  â€¢ {metric}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ’¡ IMPLICATIONS BUSINESS PRIORITAIRES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "implications = [\n",
    "    \"ğŸ¯ TIMING OPTIMAL:\",\n",
    "    f\"  â€¢ Lancer produits le {weekend_result['meilleur_jour'].lower()}\",\n",
    "    f\"  â€¢ Ã‰viter le {weekend_result['pire_jour'].lower()}\",\n",
    "    f\"  â€¢ Saison optimale: {seasonality_result['meilleure_saison']}\",\n",
    "    f\"  â€¢ Ã‰viter: {seasonality_result['pire_saison']} et {seasonality_result['pire_mois']}\",\n",
    "    \"\",\n",
    "    \"ğŸ“ˆ STRATÃ‰GIE TEMPORELLE:\",\n",
    "    f\"  â€¢ Tendance: {'Positive' if longterm_result['tendance'] > 0 else 'NÃ©gative'} ({longterm_result['evolution_annuelle']:+.4f}/an)\",\n",
    "    f\"  â€¢ Volume-QualitÃ©: {'Dilution dÃ©tectÃ©e' if longterm_result['correlation_volume_qualite'] < -0.3 else 'Pas de dilution'}\",\n",
    "    \"\",\n",
    "    \"ğŸš€ ACTIONS IMMÃ‰DIATES:\",\n",
    "    \"  1. ImplÃ©menter calendrier Ã©ditorial basÃ© sur patterns dÃ©couverts\",\n",
    "    \"  2. Optimiser timing des lancements produits\",\n",
    "    \"  3. Monitoring continue des tendances dÃ©tectÃ©es\",\n",
    "    \"  4. Segmentation communications temporelles\",\n",
    "    \"\",\n",
    "    \"ğŸ¯ MÃ‰TRIQUES Ã€ SURVEILLER:\",\n",
    "    \"  â€¢ Ã‰volution diffÃ©rentiel weekend-semaine\",\n",
    "    \"  â€¢ StabilitÃ© patterns saisonniers\", \n",
    "    \"  â€¢ DÃ©rive tendance long terme\",\n",
    "    \"  â€¢ CorrÃ©lation volume-qualitÃ©\"\n",
    "]\n",
    "\n",
    "for implication in implications:\n",
    "    print(implication)\n",
    "\n",
    "# Calcul ROI potentiel\n",
    "print(\"\\nğŸ’° ROI ESTIMÃ‰:\")\n",
    "effect_size = abs(weekend_result['effet_weekend']) + seasonality_result['ecart_saisonnier']\n",
    "optimization_potential = effect_size * 0.5  # 50% d'optimisation rÃ©aliste\n",
    "\n",
    "print(f\"  â€¢ Effet total dÃ©tectable: {effect_size:.4f} points\")\n",
    "print(f\"  â€¢ Potentiel d'optimisation: {optimization_potential:.4f} points\")\n",
    "print(f\"  â€¢ Impact relatif: {optimization_potential/df_clean['rating'].mean()*100:.2f}% d'amÃ©lioration possible\")\n",
    "\n",
    "print(\"\\nâœ… SYNTHÃˆSE COMPLÃˆTE TERMINÃ‰E !\")\n",
    "print(\"ğŸš€ PrÃªt pour implÃ©mentation business !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mangetamain-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
